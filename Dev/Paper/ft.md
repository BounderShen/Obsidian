##### 摘要
我们已经实现了一个商业级别的系统，用于提供容错虚拟机。该系统基于通过在另一台服务器上备份虚拟机来复制主要虚拟机（VM）执行的方法。我们在VMware vSphere 4.0中设计了一个完整的系统，易于使用，在普通服务器上运行，并且通常将真实应用程序的性能降低不到10％。此外，保持主要和次要VM同步执行所需的数据带宽对于几个真实应用程序而言少于20 Mbit/s，这使得可以在更长距离上实现容错。自动恢复冗余度失败后需要许多额外组件的易于使用、商业化系统超出了复制VM执行之外。我们已经设计并实施了这些额外组件，并解决了支持运行企业应用程序的VM时遇到的许多实际问题。在本文中，我们描述了我们基本设计，讨论替代设计选择以及一些实现细节，并为微型基准测试和真实应用程序提供性能结果。

#### 介绍

![](E:\IT\图片\Snipaste_2023-03-25_22-03-17.png)

实现容错服务器的常见方法是主/备份方法[1]，其中备份服务器始终可用于在主服务器失败时接管。备份服务器的状态必须始终保持与主服务器几乎相同，以便在主机故障时立即接管备份服务器，并以使故障对外部客户端隐藏且不会丢失任何数据的方式进行。复制备份服务器上的状态的一种方法是将所有主要状态（包括CPU、内存和I/O设备）的更改几乎连续地发送到备份中。然而，需要发送此状态（特别是内存中的更改）所需的带宽可能非常大。

另一种可以使用较少带宽来复制服务器的方法有时被称为状态机方法[13]。其思想是将服务建模为确定性状态机，并通过从相同初始状态启动它们并确保它们按照相同顺序收到相同输入请求来使它们保持同步。***由于大多数服务或操作都具有某些不确定性操作，因此必须使用额外协调来确保主节点和副本节点保持同步。但是，需要使主节点和副本节点保持同步所需额外信息量远小于正在发生变化（主要是内存更新）中存在于原始数据上下文中所需保存该信息量大小***。

实现协调以确保物理服务器的确定性执行[14]是困难的，特别是随着处理器频率的增加。相比之下，在虚拟化管理程序上运行的虚拟机（VM）是实施状态机方法的绝佳平台。可以将VM视为定义明确的状态机，其操作是被虚拟化机器（包括所有设备）的操作。与物理服务器一样，VM具有一些非确定性操作（例如读取时钟或中断传递），因此必须向备份发送额外信息以确保它们同步。由于虚拟化管理程序完全控制VM的执行，包括所有输入交付，因此它能够捕获关于主要VM上非确定性操作所需的所有必要信息，并在备份VM上正确地重放这些操作。

因此，***在商品硬件上可以实现基于状态机方法对虚拟机进行故障容错处理而无需进行硬件修改，从而使最新微处理器立即具有容错功能***。另外，***状态机方法所需带宽较低，允许主和备之间更大程度地分离***。例如，在校园内分布式运行复制后的虚拟机可提供比在同一建筑物内运行更高可靠性。

我们已经使用基于主/备模式在 VMware vSphere 4.0 平台上实现了容错 VM，该平台以高效的方式运行完全虚拟化的 x86 虚拟机。由于 VMware vSphere 实现了完整的 x86 虚拟机，因此我们自动能够为任何 x86 操作系统和应用程序提供容错处理。允许我们记录主执行并确保备份执行相同的基础技术称为确定性重放[15]。VMware vSphere Fault Tolerance (FT) 基于确定性重放，但添加了必要的额外协议和功能来构建一个完整的容错系统。除了提供硬件故障容错之外，我们的系统还通过在本地集群中任何可用服务器上启动新备份虚拟机来自动恢复冗余度。目前，确定性重放和 VMware FT 的生产版本仅支持单处理器 VMs。记录和回放多处理器 VM 的执行仍在进行中，并且存在显着性能问题，因为几乎每次访问共享内存都可能是非确定性操作。

Bressoud和Schneider [3]描述了一种针对HP PA-RISC平台的容错虚拟机原型实现。我们的方法类似，但出于性能原因进行了一些基本更改，并研究了许多设计替代方案。此外，我们不得不在系统中设计和实现许多额外组件，并处理许多实际问题，以构建一个完整的系统，使客户运行企业应用程序时既高效又可用。与大多数其他实际系统相似，我们只尝试处理故障停止故障[12]，这是可以在失败服务器导致错误的外部可见操作之前检测到的服务器故障。

本文其余部分如下所述。首先，我们描述了基本设计并详细说明了确保主VM失败后备份VM接管时不会丢失任何数据的基本协议。然后，我们详细介绍必须解决以构建强大、完整和自动化系统所需面对的许多实际问题。我们还描述了几个关于实施容错虚拟机而产生的设计选择，并讨论这些选择中存在的权衡取舍。接下来，我们为某些基准测试和某些真正企业应用程序提供了我们实现性能结果。最后，我们描述相关工作并做出结论。

#### 2. 基本设计

图1展示了我们提供容错虚拟机的基本设置。对于需要提供容错性的给定虚拟机（主要虚拟机），我们在不同物理服务器上运行备份虚拟机，使其保持同步并完全相同地执行，但存在一小段时间滞后。我们称这两个虚拟机处于“虚拟锁步”状态。这些VM的虚拟磁盘位于共享存储中（例如Fibre Channel或iSCSI磁盘阵列），因此可以为主要和备份VM提供输入和输出。（在第4.1节中，我们将讨论一个设计，在该设计中，主要和备份VM具有单独的非共享虚拟磁盘）。只有主要VM在网络上广告自己的存在，因此所有网络输入都会传递到主要VM。类似地，所有其他输入（例如键盘和鼠标）仅传递到主要VM。

主VM接收的所有输入都通过称为日志通道的网络连接发送到备份VM。对于服务器工作负载，主要输入流量是网络和磁盘。如下面第2.1节所讨论的那样，必要时会传输其他信息，以确保备份VM以与主VM相同的方式执行非确定性操作。结果是备份VM始终与主VM完全相同地执行。但是，超级监视程序会丢弃备份 VM 的输出，因此只有主 VM 产生实际输出并返回给客户端。如第2.2节所述，主和备用 VM 遵循特定协议（包括由备用 VM 明确确认），以确保在发生故障时不会丢失任何数据。

为了检测出是否存在失败的原始或备用 VM ，我们系统使用相关服务器之间心跳信号和监控日志通道上的流量组合来进行检测。此外，即使处于分裂大脑状态（即原始和备用服务器彼此失去联系），我们也必须确保仅有一个原始或备用虚拟机接管执行。

在以下各节中，我们提供有关几个重要领域更多详细信息：在第2.1节中，我们介绍了一些关于确定性回放技术的详细信息；在第2.2节中描述了FT协议基本规则，以确保在主VM失败时不会丢失任何数据；在第2.3节中，我们描述了检测和正确响应故障的方法。

##### 2.1 确定性重放实现

正如我们所提到的，复制服务器（或虚拟机）执行可以建模为确定性状态机的复制。如果两个确定性状态机在相同的初始状态下启动，并以相同顺序提供完全相同的输入，则它们将经过相同的状态序列并产生相同的输出。虚拟机具有广泛的输入，包括传入网络数据包、磁盘读取和键盘鼠标输入等。非确定性事件（例如虚拟中断）和非确定性操作（例如读取处理器时钟周期计数器）也会影响VM 的状态。这对于复制运行任何操作系统和工作负载上运行任何 VM 的执行存在三个挑战：
(1) 正确捕获所有必要的输入和不确定性，以确保备份虚拟机具有确定性执行，
(2) 正确应用输入和不确定性到备份虚拟机，并且
(3) 以不降低性能的方式进行。
此外，在x86微处理器中许多复杂操作都具有未定义因此是非决定论副作用。捕获这些未定义副作用并重放它们以产生相同状态还需要额外面临挑战。

VMware确定性重放[15]为VMware vSphere平台上的x86虚拟机提供了这种功能。确定性重放记录了VM的输入以及与VM执行相关的所有可能的非确定性，写入到日志文件中的一系列日志条目中。稍后可以通过从文件读取日志条目来完全重播VM执行。对于非确定性操作，记录足够的信息以允许使用相同状态更改和输出再现操作。对于定时器或IO完成中断等非确定性事件，还记录发生事件的确切指令。在回放期间，在指令流中相同点传递事件。 VMware deterministic replay实现了一种有效率高、采用各种技术（包括与AMD [2]和Intel [8]共同开发硬件计数器）进行事件记录和交付机制。

Bressoud和Schneider [3]提到将VM执行分成时期，其中诸如中断之类的不确定性事件只在时期结束时传递。时间概念似乎被用作批处理机制，因为单独在发生位置精确地传递每个中断过于昂贵。但是我们的事件交付机制足够高效，使得VMware deterministic replay无需使用时间段即可运行良好，并且每个中断都会在其发生时被有效地交付到正确指令处进行回放

##### 2.2 FT协议

对于VMware FT，我们使用确定性重放来生成必要的日志条目以记录主VM的执行情况，但是我们不会将日志条目写入磁盘，而是通过日志通道将它们发送到备份VM。备份VM实时重放这些条目，因此与主VM完全相同地执行。然而，在日志通道上，我们必须增加严格的FT协议以确保实现容错性。我们的基本要求如下：输出要求：如果备份VM在主机故障后接管，则备份VM将继续以与主机向外部世界发送的所有输出完全一致的方式执行。

![](E:\IT\图片\Snipaste_2023-03-25_22-03-04.png)

请注意，在故障转移发生后（即主 VM 失败后备份 VM 接管），由于执行期间发生的许多非确定性事件，备份 VM 可能会开始以与主 VM 不同的方式执行。但是，只要备份 VM 满足输出要求，在故障转移到备份 VM 时不会丢失任何外部可见状态或数据，并且客户端将不会注意到服务中断或不一致。

可以通过延迟任何外部输出（通常为网络数据包）来确保输出要求，直到备份 VM 收到允许其至少重放执行到该输出操作点的所有信息。一个必要条件是备份VM必须已经接收了在输出操作之前生成的所有日志条目。这些日志条目将使它执行到最后一个日志条目所在位置。然而，假设在主机执行完输出操作之后立即发生故障，则备用虚拟机必须知道它必须继续重放直至达到输出操作点，并仅在那一点上“上线”（停止重放并接管作为主VM）。如果备用虚拟机在进行输出操作之前就启动，则某些非确定性事件（例如传递给虚拟机的计时器中断）可能会更改其执行路径。

鉴于上述限制，强制执行输出要求的最简单方法是在每个输出操作中创建一个特殊的日志条目。然后，可以通过以下具体规则来强制执行输出要求：输出规则：主虚拟机在外部世界发送输出之前，必须等到备份虚拟机接收并确认与产生该输出操作相关联的日志条目。

如果备份虚拟机已经接收到所有的日志条目，包括产生输出操作的日志条目，则备份虚拟机将能够精确地复制主要虚拟机在该输出点处的状态，因此如果主要虚拟机死亡，则备份将正确地达到与该输出一致的状态。相反，如果备份虚拟机在没有接收到所有必要的日志条目的情况下接管，则其状态可能会迅速发散，使其与主服务器的输出不一致。 输出规则在某些方面类似于[11]中描述的方法，在该方法中，“外部同步”IO实际上可以被缓冲，只要它实际上是在下一个外部通信之前写入磁盘即可。

请注意，输出规则并未说明停止执行主VM所需做出任何措施。我们只需要延迟发送输出即可，但VM本身可以继续执行。由于操作系统使用异步中断进行非阻塞网络和磁盘输出以指示完成情况，因此VM可以轻松地继续执行，并且不一定会立即受到对输出延迟的影响。相比之下，在先前工作[3、9]中通常表明，在从主VM获取所有必要信息之前，请完全停止主VM以进行输出。

例如，在图2中，我们展示了FT协议的要求。该图显示主VM和备份VM上事件的时间线。从主线到备份线的箭头表示日志条目的传输，而从备份线到主线的箭头表示确认。异步事件、输入和输出操作的信息必须作为日志条目发送并得到确认。如图所示，对外部世界进行输出将被延迟，直到主VM收到来自备份VM已接收与输出操作相关联的日志条目的确认为止。鉴于遵循了输出规则，则备份虚拟机将能够以与主服务器最后一次输出一致的状态接管控制权

我们无法保证在故障转移情况下所有输出都只产生一次。如果主节点打算发送一个输出，而没有使用两阶段提交的事务，则备份无法确定主节点是在发送其最后一个输出之前还是之后立即崩溃。幸运的是，网络基础设施（包括常用的TCP）被设计为处理丢失数据包和相同（重复）数据包。请注意，在主服务器发生故障时，传入到主服务器的数据包也可能会丢失，并因此未能传递给备份服务器。但是，由于与服务器故障无关的任何原因都可能导致传入数据包被删除，因此网络基础设施、操作系统和应用程序都编写了以确保它们可以弥补丢失的数据包。

##### 2.3 检测和响应失败

如上所述，主VM和备份VM必须在另一个VM似乎已经失败时快速响应。如果备份VM失败，则主VM将变为活动状态 - 即离开记录模式（因此停止在日志通道上发送条目）并开始正常执行。如果主VM失败，则备份VM应该类似地进入活动状态，但是这个过程有点更加复杂。由于其执行滞后性，备份VM可能会有许多日志条目已经接收并确认，但尚未被消耗，因为备份VM尚未达到适当的执行点。备份 VM必须继续从日志条目重放其执行，直到它消耗了最后一个日志条目为止。此时，备用 VM将停止重播模式，并开始作为普通 VM 执行。实质上，备用 VM 已经升级为主要 VM（现在缺少一台备用 VM）。由于它不再是一台 备用 服务器 ，新的 主要 服务器 现在将 在 客户操作系统 进行输出操作时向外部世界产生输出 。在转换到正常模式期间 ，可能需要进行某些设备特定的操作以使此输出正确发生 。特别地 ，对于网络连接而言 ， VMware FT 自动广告 新 的 主要虚拟机 的 MAC 地址，在物理网络交换机中知道新的主虚拟机位于哪个服务器上。此外，新晋升的主VM可能需要重新发出一些磁盘IO（如第3.4节所述）。

有许多可能的方法来尝试检测主VM和备份VM的故障。 VMware FT使用运行容错虚拟机的服务器之间的UDP心跳来检测服务器是否已经崩溃。此外，VMware FT监视从主到备份 VM发送的日志流量以及从备份 VM发送到主 VM 的确认。由于定期计时器中断，对于正常工作的客户操作系统而言，日志流量应该是规律且永不停止。因此，如果日志条目或确认停止了超过特定超时时间（大约几秒钟），则会宣布失败 。

然而，任何此类故障检测方法都容易出现分裂大脑问题。如果备份服务器停止从主服务器接收心跳信号，则可能表明主服务器已经失败，也可能只是表示所有仍在运行的服务器之间的网络连接已经丢失。如果备份虚拟机在实际上仍在运行的情况下启动，则很可能会导致数据损坏和客户端与虚拟机通信时出现问题。因此，在检测到故障时，我们必须确保只有一个主要或备份虚拟机可以启动。为了避免分裂大脑问题，我们利用存储虚拟机的共享存储器来解决这个问题。当主要或备份虚拟机想要启动时，它会对共享存储器执行原子测试并设置操作。如果该操作成功，则允许该虚拟机启动；否则说明另一个虚拟机已经启动，并且当前的虚拟机将自己停止（“自杀”）。如果该VM无法访问共享存储器以执行原子操作，则它将等待直到可以访问为止。请注意，如果由于存储网络中发生某些故障而无法访问共享存储器，则该VM很可能无法执行有用工作，因为虚拟磁盘位于同一共享存储器上。因此，使用共享存储器来解决分裂大脑问题不会引入任何额外的不可用性。
设计的最后一个方面是，一旦发生故障并且其中一个VM已经启动，则VMware FT会自动通过在另一台主机上启动新的备份虚拟机来恢复冗余。尽管这个过程在大多数以前的工作中没有涉及到，但它对于使容错虚拟机有用是基本的，并需要仔细设计。更多详细信息请参见第3.1节。

#### 3. FT的实际实施

第二部分描述了我们FT的基本设计和协议。然而，为了创建一个可用、强大且自动化的系统，还需要设计和实现许多其他组件。

##### 3.1启动和重新启动FT

必须设计的最大附加组件之一是启动备份虚拟机以与主要虚拟机处于相同状态的机制。在发生故障后重新启动备份虚拟机时，也将使用此机制。因此，该机制必须适用于运行中的主要虚拟机，其处于任意状态（即不仅仅是正在启动）。此外，我们希望该机制不会显着干扰主要虚拟机的执行，因为这将影响到 VM 的任何当前客户端。

对于VMware FT，我们改编了VMware vSphere的现有`VMotion`功能。 VMware `VMotion` [10] 允许将正在运行的虚拟机从一个服务器迁移到另一个服务器，并且最小化中断 - 虚拟机暂停时间通常不到一秒钟。 我们创建了一种修改后的`VMotion`形式，在远程服务器上创建虚拟机的精确运行副本，但不会破坏本地服务器上的虚拟机。 也就是说，我们修改后的FT `VMotion`将虚拟机克隆到远程主机而不是迁移它。 `FT VMotion`还设置日志记录通道，并使源虚拟机进入作为主要日志记录模式，目标虚拟机进入重放模式作为新备份。 像普通`VMotion`一样，`FT VMotion`通常会在少于一秒钟内中断主要虚拟机的执行。 因此，在运行中启用FT是一项简单、非干扰性操作。

启动备份虚拟机的另一个方面是选择在哪个服务器上运行它。容错虚拟机在具有共享存储访问权限的服务器集群中运行，因此所有虚拟机通常都可以在集群中的任何一台服务器上运行。这种灵活性使得 VMware vSphere 可以在一个或多个服务器故障时恢复 FT 冗余。VMware vSphere 实现了维护管理和资源信息的集群服务。当发生故障并且主要 VM 现在需要新的备份 VM 来重新建立冗余时，主要 VM 会通知集群服务它需要一个新的备份。根据资源使用情况和其他限制条件，集群服务确定最佳服务器来运行备份 VM，并调用 FT 迁移来创建新的备份 VM。结果是，在服务器故障后几分钟内，VMware FT 通常可以重新建立 VM 冗余，而不会对容错虚拟机执行产生任何明显中断。

![](E:\IT\图片\Snipaste_2023-03-26_12-06-04.png)

##### 3.2管理日志通道

在管理日志通道上的流量时，有许多有趣的实现细节。在我们的实现中，虚拟化程序为主VM和备份VM维护一个大型缓冲区以记录日志条目。当主VM执行时，它会将日志条目写入日志缓冲区；同样地，备份VM从其自己的日志缓冲区读取日志条目。尽快将主VM的日志缓冲区内容刷新到记录通道，并且一旦到达就立即从记录通道读取并写入备份VM的日志缓冲区。每次从网络中读取一些日志条目并写入其自己的日志缓冲区后，备份会向主机发送确认信息。这些确认允许 VMware FT 确定何时可以发送由输出规则延迟的输出。图3说明了此过程。

如果备份 VM 在需要读取下一个日志条目时遇到空白的 日 志 缓 冲 区 ， 它 将 停 止 执 行 直 到 有 新 的 日 志 条 目 可 用 。由于备份 VM 不与外部进行通信，因此此暂停不会影响任何 VM 的客户端。

同样地，如果主 VM 在需要写入新 日 志 条 目 时 遇 到 满 的 日 志 缓 冲 区 ， 它 必 须 停 止 执 行 直 到 日 志 条 目 能 够 被 冲 出 。这种执行停止是一种自然的流量控制机制，当主 VM 以过快的速度生成日志条目时会减慢其速度。但是，此暂停可能会影响 VM 的客户端，因为主VM将完全停止并且无法响应直到它可以记录其条目并继续执行。因此，我们的实现必须设计成最小化主要日志缓冲区填满的可能性。

主要日志缓冲区可能会填满的一个原因是备份虚拟机执行速度过慢，因此消耗日志条目的速度也很慢。一般来说，备份虚拟机必须能够以与主要虚拟机记录执行相同的速度重放执行。幸运的是，在 VMware 确定性重放中记录和重播的开销大致相同。然而，如果托管备份 VM 的服务器负载过重（因此在资源上超额配置），则尽管备份超级管理程序 VM 调度程序尽最大努力，但备份 VM 可能无法获得足够的 CPU 和内存资源以像主要 VM 一样快地执行。

除了避免意外暂停导致日志缓冲区填满之外，我们不希望执行延迟变得太大还有另一个原因。如果主要 VM 失败，则备份 VM 必须通过回放其已经确认接收到的所有日志条目来“赶上”，然后才能启动并开始与外部世界通信。完成回放所需时间基本上等于故障发生时点处的执行延迟时间，因此使备份恢复正常所需时间大约等于故障检测时间加上当前执行延迟时间。因此，我们不希望执行延迟时间过长（超过一秒钟），因为这将增加故障转移时间。

因此，我们有一个额外的机制来减慢主要 VM 的速度，以防备份 VM 落后太多。在发送和确认日志条目的协议中，我们发送附加信息以确定主要和备份 VM 之间的实时执行延迟。通常情况下，执行延迟小于100毫秒。如果备份 VM 开始出现显着的执行延迟（例如超过1秒），VMware FT 就会通过通知调度程序给予稍微较少量的 CPU 来减缓主要 VM 的速度（最初仅减少几个百分点）。我们使用缓慢反馈循环逐渐确定适当的 CPU 限制值，使得主要虚拟机可以与其匹配执行。如果备份虚拟机继续落后，则我们将继续逐步降低主要虚拟机的 CPU 限制；相反地，如果备份虚拟机赶上了，则我们将逐渐增加主要虚拟机的 CPU 限制直到备份虚拟机再次略有滞后。

请注意，在极端压力下才会非常罕见地放慢主要 VM，并且通常只发生在系统性能受到极大影响时。第5节中的所有性能数字都包括任何此类放慢的成本。

##### 3.3在FT VMS 操作

另一个实际问题是处理可能应用于主VM的各种控制操作。例如，如果明确关闭了主VM，则备份VM也应停止，并且不尝试启动。另一个例子是，在主要资源管理更改（例如增加CPU共享）时，也应将其应用于备份。对于这些类型的操作，从主到备份在日志通道上发送特殊的控制条目，以便在备份上执行适当的操作。

一般来说，大多数VM上的操作都只能在主VM上启动。然后，VMware FT会发送任何必要的控制条目以导致备份VM上进行适当更改。唯一可以独立在主和备份虚拟机上完成的操作是 VMotion 。即可以将 主和 备  独立地迁移到其他宿主机器中去.请注意 ， VMware FT 确保两个 VM 都不会移动到另一个 VM 所在 的服务器 上 ，因为那样就不能再提供容错性了。

与普通 VMotion 相比 ， 主 VM 的 VMotion 增加了一些复杂性 ，因为 在适当时间 备  件 必须从源 主 虚拟机断开连接并重新连接到目标 主 虚拟机 。 备 件 的 Vmotion 具有类似问题 ，但增加了额外复杂度 。 对于正常情况下的 VMotion ，我们要求在 VMotion 发生最终切换时将所有未完成的磁盘 IO 静默（即完成）。对于主VM，这种静默处理很容易，只需等待物理IO完成并将这些完成传递给VM即可。但是，对于备份VM，则没有简单的方法可以在任何所需点上导致所有IO都被完全执行，因为备份VM必须重放主VM的执行，并在相同的执行点上完成IO。主虚拟机可能正在运行一个工作负载，在正常执行期间始终存在磁盘I / O。 VMware FT 有一种独特的方法来解决此问题。当备份虚拟机处于 VMotion 的最后切换点时，它通过日志通道请求主虚拟机暂时使其所有 I/O 静默 。然后备份虚拟机的 I/O 将自然地在重放静音操作期间以单个执行点被静音处理。

##### 3.4磁盘输入输出出现的问题

有一些与磁盘IO相关的微妙实现问题。首先，由于磁盘操作是非阻塞的，因此可以并行执行，同时访问相同磁盘位置的并发磁盘操作可能会导致不确定性。另外，我们的磁盘IO实现直接使用DMA从虚拟机内存中读取/写入数据，因此同时访问相同内存页的并发磁盘操作也可能会导致不确定性。我们通常的解决方案是检测任何这样的IO竞争（这种情况很少），并强制使这些竞争状态下的磁盘操作在主备份上以相同方式顺序执行。
其次，一个磁盘操作也可能与VM中应用程序（或OS）对内存进行访问产生竞争关系，因为通过DMA直接访问VM内存。例如，在VM中运行应用程序/OS正在读取一个内存块时如果同时进行了该块数据的读取，则结果将是不确定性。尽管这种情况很少见但我们必须检测它，并在出现时处理它。其中一种解决方案是临时设置页面保护来保护作为目标进行I/O 操作 的页面, 如果 VM 原本要访问正在等待 I/O 完成 的页面, 则会触发一个陷阱, VM 将被暂停直到 I/O 操作完成。由于更改页面上的 MMU 保护是一项昂贵的操作，我们选择使用反弹缓冲区。反弹缓冲区是一个临时缓冲区，其大小与磁盘操作访问的内存相同。将修改后的磁盘读取操作读取指定数据到反弹缓冲区，并在传递IO完成时仅将数据复制到客户端内存中。类似地，对于磁盘写入操作，要发送的数据首先被复制到反弹缓冲器中，并修改了磁盘写入以从反弹缓冲器中写入数据。使用反弹缓冲器可能会减慢磁盘操作速度，但我们没有看到它导致任何明显性能损失。

第三，当主服务器发生故障并且备份接管时，与磁盘IO相关的一些问题仍未解决。新晋升的主虚拟机无法确定磁盘IO是否已经成功完成。此外，由于在备份虚拟机上没有外部发出的磁盘IO请求，因此这些操作将不会有明确的完成信号，在新晋升的主虚拟机继续运行时最终会导致VM中的客户操作系统启动中止或重置过程。我们可以发送一个错误完成指示每个IO失败，因为即使IO成功完成也可以返回错误是可接受的。但是，客户OS可能对来自其本地磁盘的错误反应不佳。相反，在备份VM实施go-live过程期间重新发出挂起状态下未处理完毕（i.e. idempotent） 的 IOs 。由于我们消除了所有竞争，并且所有I/O直接指定访问哪些内存和磁盘块，因此即使它们已经成功完成（即它们具有幂等性），这些磁盘操作也可以被重新执行。

##### 3.5网络IO实现的问题

VMware vSphere为虚拟机网络提供了许多性能优化。其中一些优化是基于超级监视器异步更新虚拟机网络设备的状态。例如，当VM执行时，接收缓冲区可以直接由超级监视器进行更新。不幸的是，这些对VM状态的异步更新会增加非确定性。除非我们能够保证所有更新在主节点和备份节点上发生在指令流中的相同点上，否则备份节点的执行可能会与主节点不同。

FT网络仿真代码最大的变化是禁用异步网络优化。异步地使用传入数据包来更新VM环形缓冲区的代码已被修改为强制客户机陷入到超级监视器中，在那里可以记录并应用这些更新到VM中。类似地，正常情况下从传输队列中拉出数据包以进行异步处理的代码也被禁用，并且通过陷阱到超级监视器来完成传输（除非如下所述）。

消除网络设备的异步更新以及描述2.2节中发送数据包延迟带来了一些性能挑战。我们采取了两种方法来改善运行FT时VM网络性能。首先，我们实现了集群优化以减少VM陷阱和中断次数。当VM以足够高比特率流式传输数据时，超级监视器可以每组数据包进行一次传输陷阱，并且在最佳情况下，零次陷阱，因为它可以将数据包作为接收新数据包的一部分进行传输。同样地，超级监视器可以通过仅针对一组数据包发布中断来减少VM接收入站数据包时的中断次数。

我们第二个网络性能优化涉及减少已发送数据包的延迟。如前所述，超级监视器必须延迟所有已发送的数据包直到获得备份节点适当日志条目的确认。减少传输延迟的关键是缩短向备份节点发送日志消息并获取确认所需时间。我们在这个领域主要采取了两种优化措施：确保发送和接收日志条目和确认都可以在没有任何线程上下文切换的情况下完成；VMware vSphere超级监视器允许函数注册到TCP堆栈中，在类似于Linux任务let 的推迟执行上下文（deferred-execution context）中调用该函数以处理任何接收到TCP 数据时快速处理备份节点上任何传入日志消息和主节点接收到的任何确认而不需要进行线程上下文切换。此外，在主VM排队要传输一个数据包时，我们通过安排推迟执行上下文来强制立即刷新相关输出日志条目的日志（如2.2节所述）。

![](E:\IT\图片\Snipaste_2023-03-26_12-07-48.png)

#### 4.设计替代方案

在我们实现VMware FT时，我们探索了许多有趣的设计替代方案。在本节中，我们将探讨其中一些替代方案

##### 4.1 共享和非共享磁盘

在我们的默认设计中，主VM和备份VM共享相同的虚拟磁盘。因此，如果发生故障转移，则共享磁盘的内容自然是正确且可用的。实际上，共享磁盘被认为是外部于主VM和备份VM之外的东西，因此对共享磁盘的任何写操作都被视为与外界通信。因此，只有主VM才会实际进行对磁盘的写入，并且必须根据输出规则延迟对共享磁盘进行写入。
另一种设计是让主VM和备份VM具有单独（非共享）虚拟硬盘。在这种设计中，备份VM确实会将所有硬盘写入其虚拟硬盘，并通过这样做自然地使其虚拟硬盘内容与主要 VM 的虚拟硬 盤内容保持同步。图4说明了这种配置方式。在非共享硬件情况下，虚拟硬件基本上被认为是每个 VM 内部状态 的一部分。因此，在不需要按输出规则延迟时可以进行主要数据存储器的写操作 。当无法访问到主 VM 和备份 VM 时 ， 非 共 用 设 计 是 非 常 有 用 的 。这 可 能 是 因 为 共 享 存 储 不 可 用 或 太 昂 贵 ， 或 者 是 因 为 运 行 主 VM 和备份VM的服务器相距甚远（“长距离FT”）。非共享设计的一个缺点是，在启用容错性时，必须以某种方式显式同步虚拟硬盘的两个副本。此外，在故障后，磁盘可能会失去同步，因此在备份VM在故障后重新启动时必须明确地重新同步它们。也就是说，FT VMotion不仅必须同步主VM和备份VM的运行状态，还必须同步它们的磁盘状态。
在非共享硬件配置中，可能没有共享存储可用于处理分裂脑情况。在这种情况下，系统可以使用其他外部解决方案作为补充措施，例如双方都能够与第三方服务器通信。如果服务器是集群中具有多个节点，则系统可以选择基于集群成员身份 的大多数算法。在这种情况下 ，只有当 VM 运行 在 包 含 原 始 节 点 大 多 数 的 沟 通 子 集 中 的服 务器 上 才 允 许 它 上线。

##### 4.2 在备份虚拟机上执行磁盘读取

在我们的默认设计中，备份虚拟机从未从其虚拟磁盘（共享或非共享）中读取。由于磁盘读取被视为输入，因此将磁盘读取结果通过日志通道发送到备份虚拟机是很自然的。另一种设计是让备份虚拟机执行磁盘读取，从而消除对磁盘读取数据进行记录的需要。这种方法可以大大减少工作负载上产生的日志通道流量，但是它也有一些微妙之处。它可能会降低备份虚拟机的执行速度，因为备份虚拟机必须执行所有的磁盘读操作，并且如果在达到主要VM完成时它们还没有物理完成，则必须等待。
此外，在处理失败的磁盘读操作时还必须做一些额外工作。如果主VM进行了一个成功的硬盘读操作但相应的备份硬件却失败了，则必须重试由后者发起并成功地完成该硬件所需数据传输过来以确保两个内存中保存着同样内容；反之亦然：如果主VM进行了一个不成功 的硬件阅览，则目标内存区域能够被成功的备份虚拟机所复制，因此内存区域的内容必须通过日志通道发送到备份中。
最后，如果使用共享磁盘配置，则存在一个细微之处。如果主VM对特定磁盘位置进行读取，并在不久之后写入同一磁盘位置，则必须延迟磁盘写入操作，直到备份VM执行了第一次磁盘读取。这种依赖关系可以被正确地检测和处理，但会增加实现的额外复杂性。在第5.1节中，我们给出了一些性能结果指示，在真实应用程序中，在备份上执行硬件阅览可能会导致略微降低吞吐量（1-4％），但也可以显着减少日志带宽。因此，在日志通道带宽非常有限的情况下，在备份虚拟机上执行硬件阅览可能是有用的。

#### 5性能评估

在本节中，我们对VMware FT的性能进行了基本评估，包括一些应用工作负载和网络基准测试。对于这些结果，我们在相同的服务器上运行主备虚拟机，每个服务器都配备有8个英特尔Xeon 2.8 GHz CPU和8 GB RAM。这两台服务器通过10 `Gbit/s`交叉网络连接，尽管在所有情况下使用的网络带宽远低于1 `Gbit/s`。两台服务器都通过标准4 `Gbit/s`光纤通道网络从`EMC Clariion`访问其共享虚拟磁盘。用于驱动某些工作负载的客户端通过1 `Gbit/s`网络连接到服务器。
我们在性能结果中评估的应用程序如下所示。SPECJbb2005是一个业界标准Java应用程序基准测试，非常依赖CPU和内存，并且很少进行IO操作。Kernel Compile是一个工作负载，在其中编译Linux内核。此工作负载执行一些磁盘读写操作，并且由于创建和销毁许多编译进程而非常依赖CPU和MMU资源。`Oracle Swingbench`是一个工作负载，在其中`Swingbench OLTP`（在线事务处理）工作量驱动Oracle 11g数据库。此工作负载执行大量磁盘和网络IO，并具有80个同时数据库会话。MS-SQL DVD Store是一个工作负载，在其中Microsoft SQL Server 2005数据库由DVD Store基准测试驱动，该测试具有16个同时客户端。

![](E:\IT\图片\Snipaste_2023-03-26_12-08-33.png)

![](E:\IT\图片\Snipaste_2023-03-26_12-08-53.png)

##### 5.1 基本性能结果

表1给出了基本的性能结果。对于列出的每个应用程序，第二列给出了在运行服务器工作负载的虚拟机上启用FT时应用程序性能与未启用FT时相比的比率。性能比率是这样计算的，即小于1的值表示FT工作负载较慢。显然，在这些代表性工作负载上启用FT所需开销不到10％。SPECJbb2005完全受计算限制，并且没有空闲时间，但由于除定时器中断之外几乎没有非确定事件而表现良好。其他工作负载执行磁盘IO并具有一些空闲时间，因此某些FT开销可能被隐藏，因为FT虚拟机具有更少的空闲时间。然而，总体结论是VMware FT可以支持带有相当低性能开销的容错VM。
在表格第三列中，我们提供了运行这些应用程序时发送到日志通道上数据平均带宽。对于这些应用程序来说，记录带宽非常合理，并且易于通过1 `Gbit` / s网络满足要求。实际上，低带宽要求表明多个FT工作负载可以共享同一个1 `Gbit / s`网络而不会产生任何消极的性能影响。
对于运行Linux和Windows等常见客户操作系统的VM，我们发现当客户OS处于空闲状态时，典型的记录带宽为0.5-1.5 Mbits / sec。 “空闲”带宽在很大程度上是记录定时器中断传递的结果。对于具有活动工作负载的VM，日志记录带宽由必须发送到备份的网络和磁盘输入主导 - 接收到的网络数据包和从磁盘读取的磁盘块。因此，在具有非常高网络接收或磁盘读取带宽应用程序中，日志通道的带宽可能比表1中测量值高得多。对于这些类型的应用程序来说，日志通道的带宽可能成为一个瓶颈，特别是如果还有其他使用日志通道。
许多实际应用程序所需低廉且合理地使基于重放容错技术在使用非共享磁盘进行远距离配置方面变得非常吸引人。对于主备之间可能相隔1-100公里长距离配置而言，光纤可以轻松支持100-1000 Mbit / s 的带宽，并且延迟小于10毫秒。对于表格1中列出应用程序来说，100-1000 Mbit / s的带宽应该足以实现良好性能。但是，请注意，主备之间额外的往返延迟可能会导致网络和磁盘输出被延迟高达20毫秒。长距离配置仅适用于客户端可以容忍每个请求增加这样的附加延迟的应用程序。

对于两个最需要磁盘的应用程序，我们已经测量了在备份虚拟机上执行磁盘读取（如第4.2节所述）与通过日志通道发送磁盘读取数据对性能的影响。对于`Oracle Swingbench`，当在备份虚拟机上执行磁盘读取时，吞吐量约降低了4％；对于MS-SQL DVD Store，则约降低了1％。同时，`Oracle Swingbench`的日志带宽从`12 Mbits` / sec减少到3 `Mbits / sec`；MS-SQL DVD Store则从`18 Mbits` / sec减少到`8 Mbits / sec`。显然，在具有更大磁盘读取带宽的应用程序中，带宽节省可能会更大。正如第4.2节中提到的那样，在备份虚拟机上执行磁盘读取时性能可能会略微下降。但是，在日志通道带宽受限（例如长距离配置）的情况下，在备份虚拟机上执行磁盘读取可能很有用。

##### 5.2 网络基准测试

我们的系统在进行网络基准测试时可能会面临许多挑战。首先，高速网络可能具有非常高的中断率，这需要以非常高的速度记录和重放异步事件。其次，接收数据包速率很快的基准测试将导致大量日志流量，因为所有这些数据包都必须通过日志通道发送到备份服务器。第三，在发送数据包时也会受到输出规则的限制，该规则延迟了从客户端发送网络数据包直至获得来自备份服务器适当确认信号后才能继续发送。此延迟将增加对客户端测量出来的延迟时间，并且由于网络协议（如TCP）必须随着往返延迟时间增加而降低网络传输速率，因此还可能降低向客户端提供的带宽。

表2给出了我们使用标准`netperf`基准测试所做各种测量结果。在所有这些测量中，客户机虚拟机和主要虚拟机通过1 `Gbit/s` 网络连接。前两行显示了主要和备份主机之间连接1 `Gbit/s` 日志通道时发射和接收性能情况；第三行和第四行显示了主要服务器与备份服务器之间连接10 Gbit/s 日志通道时发射和接收性能情况，该通道不仅具有更高的带宽，而且延迟也比1 Gbit/s 网络低。粗略地说，在1 Gbit/s 连接下，超级管理程序之间的ping时间约为150微秒，在10 Gbit/s 连接下约为90微秒。

当FT未启用时，主要虚拟机可以实现与1 Gbit/s线速率相近（940 Mbit/s）的传输和接收性能。在对于接收工作负载启用FT时，由于所有传入网络数据包都必须通过日志通道发送，因此日志带宽非常大。如图所示，在使用1 Gbit / s 日志网络进行测试时会出现瓶颈问题；但是在使用10Gbps日志网络进行测试时影响较小。在对于发射工作负载启用FT时，并不记录已经发射数据包中的数据内容，但是需要记录网络中断事件。由于记录带宽较低，则可达到比网络接收带宽更高的可达到的最大值。

总体而言, 我们看到 FT 可以显著限制极高传输和接受速率下的网络带宽, 但仍然可以实现很高绝对速率.

#### 6. 相关工作

`Bressoud`和Schneider [3]描述了通过完全包含在hypervisor级别的软件实现虚拟机容错的初始想法。他们通过针对具有HP PA-RISC处理器的服务器的原型演示了通过将备份虚拟机与主要虚拟机保持同步的可行性。然而，由于PA-RISC架构的限制，他们无法实现完全安全、隔离的虚拟机。此外，他们没有实施任何故障检测方法或尝试解决第3节中描述的任何实际问题。更重要的是，他们对FT协议施加了许多不必要的约束条件。首先，他们强制执行时期概念，在这个概念中异步事件被延迟到一组时间间隔结束之前。时期概念是不必要的——可能是因为它们不能有效地回放单个异步事件所以才会强制执行它。其次，他们要求主VM停止执行直到备份接收并确认所有先前日志条目为止。然而，只有输出本身（如网络数据包）必须被延迟——主VM本身可以继续执行。
`Bressoud` [4]描述了一个在操作系统（`Unixware`）中实现容错性，并因此为运行在该操作系统上所有应用程序提供容错性的系统。系统调用接口成为必须以确定性方式复制的操作集。这项工作与基于hypervisor的工作具有类似的限制和设计选择。

Napper等人[9]和Friedman和Kama [7]描述了容错Java虚拟机的实现。他们遵循与我们类似的设计，通过日志通道发送有关输入和非确定性操作的信息。像`Bressoud`一样，他们似乎没有专注于检测故障并在故障后重新建立容错能力。此外，他们的实现仅限于为在Java虚拟机中运行的应用程序提供容错能力。这些系统试图处理多线程Java应用程序的问题，但要求所有数据都由锁正确保护或对访问共享内存进行序列化。

Dunlap等人[6]描述了针对在`paravirtualized`系统上调试应用软件的确定性重放实现。我们的工作支持任意运行在虚拟机内部操作系统，并为这些VMs实现容错支持，这需要更高水平稳定性和性能。

Cully等人[5]描述了一种替代方法来支持容错VMs及其在名为Remus项目中的实施。采用该方法，在执行过程中反复检查主VM状态并将其发送到备份服务器以收集检查点信息。必须非常频繁地执行检查点（每秒多次），因为必须延迟外部输出直到已发送并确认以下检查点才可以进行下一个步骤。该方法优点是同样适用于单处理器和多处理器VM。主要问题在于，该方法需要非常高的网络带宽要求，以便在每个检查点中发送内存状态的增量更改。 [5]中呈现的Remus结果显示，在使用1 Gbit / s网络连接传输内存状态更改时，尝试执行40次检查点每秒钟进行内核编译和SPECweb基准测试时出现100％至225％的减速。有许多优化可能对降低所需的网络带宽有用，但不清楚是否可以通过1 Gbit / s连接实现合理性能。相比之下，我们基于确定性重放的方法可以实现少于10％的开销，并且主机和备份主机之间仅需要不到20 Mbit / s 的带宽即可运行多个真实应用程序。

#### 7. 结论和未来工作

我们在VMware vSphere中设计和实现了一个高效完整的系统，为集群中运行的虚拟机提供容错（FT）。我们的设计基于使用VMware确定性重放，在另一台主机上通过备份虚拟机复制主要虚拟机的执行。如果运行主要虚拟机的服务器失败，则备份虚拟机立即接管，没有中断或数据丢失。

总体而言，在通用硬件上使用VMware FT下容错虚拟机的性能非常出色，并且对于某些典型应用程序显示不到10％ 的开销。 VMware FT大部分性能成本来自于使用VMware确定性重放保持主和备份 VM同步时产生的开销。因此， VMware FT低延迟源自于VMware确定性重放效率高。此外，保持主和备份同步所需日志记录带宽通常相当小，通常少于20 Mbit / s。由于在大多数情况下日志记录带宽很小，因此似乎可以实现将主和备份 VM隔离长距离（1-100公里）配置方案以防止整个站点故障等灾难发生 。值得注意的是，日志流通常是可压缩的，并且简单压缩技术可以显着减少日志记录带宽并增加一些额外的CPU开销。

我们使用VMware FT的结果表明，可以基于确定性重放构建高效实现容错虚拟机。这样的系统可以透明地为运行任何操作系统和应用程序的虚拟机提供容错能力，并具有最小化开销。但是，对于容错虚拟机系统对客户有用，它还必须是强大、易于使用和高度自动化的。一个可用的系统需要许多其他组件来复制执行VM之外。特别是，VMware FT在故障后自动恢复冗余性，通过在本地集群中找到合适的服务器并在该服务器上创建新备份 VM 来完成此操作。通过解决所有必要问题，我们已经证明了一个可用于客户数据中心中真实应用程序的系统。

通过确定性重放实现容错的一个权衡是，目前仅针对单处理器虚拟机有效地实现了确定性重放。然而，单处理器虚拟机已经足够应对各种工作负载，特别是物理处理器不断变得更加强大。此外，许多工作负载可以通过使用许多单处理器虚拟机进行扩展来代替使用一个较大的多处理器虚拟机进行扩展。高性能回放多处理器虚拟机是研究的一个活跃领域，并且可以在微处理器中提供一些额外的硬件支持来潜在地启用它。其中一个有趣的方向可能是扩展事务内存模型以促进多处理器回放。
将来，我们还有兴趣将我们的系统扩展到解决部分硬件故障问题。通过部分硬件故障，我们指服务器中功能或冗余性部分丢失但不会导致数据损坏或丢失的情况。例如，在VM上失去所有网络连接或在物理服务器上失去冗余电源等都属于这种情况。如果主要VM运行的服务器发生部分硬件故障，在许多情况下（但并非全部），立即切换到备份VM将非常有利。这样的故障转移可以立即恢复关键VM的完整服务，并确保VM快速从潜在不可靠的服务器上移动。