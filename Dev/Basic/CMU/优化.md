#### 前言
1. 当我们去做些更为复杂的查询和join操作时,不同⽅法间的性能差距可能就不是那么明显了.这就是⾼端数据库系统（诸如：Oracle，DB2，Teradata和SQL server）和开源数据库系统 的区别所在了，贵有贵的道理
2. PostgreSQL依然很优秀,但它的查询优化器并不如SQL server那样来得成熟
#### 条件触发
1. 当我们查看我们的查询计划时，如果我们查询中的某些部分满⾜了我们知道的某种条件，那么，我们就会触发⼀条规则，就可以对查询做一些改造或者重写
2. 我们可能需要去查看System Catalog，我们得通过它来知道我们的数据库⻓啥样，我们的表 ⻓啥样
3. catalog中所放的是⼀堆元数据，它描述了我有哪些表，哪些列，表中的属性有哪些，对于这些规则来说，我们得去查看Catalog来理解我们底层的那些表中有哪些东⻄，但实际上我们并不需要去查看这些数据是什么
4. 在不需要实际去查看表的情况下，我们通过这些规则就可以知道这⾥⾯tuple实际包含的定义 信息
##### cost-bases search
1. 你知道的，你不需要去查看数据,如果使⽤的是这种⽅式，那么你就得以某种⽅式去查看数据
2. 思想是：我们会去枚举该SQL所有可能的不同查询⽅案，并通过某种智能的⽅式去掉那些多余或者愚蠢 的⽅案。然后，我们会通过使⽤某种成本模型来预估所有这些不同⽅案的执⾏成本
##### 架构详述
1. 第一阶段：以某种方式对SQL重写，会使⽤⼀些额外的信息对它进⾏标记，表示你可以在这个服务器节点或者这个磁盘上找到这 张表
2. 第二阶段：将SQL查询转换为抽象语法树，并将语法树转入到binder中
3. binder是负责将我们SQL查询中所引⽤的那些命名对象转换为某种内部标识符，通过询问System catalog来做到这点
4. binder所要输出的东⻄叫做逻辑计划，逻辑计划指的是，从⼀个⾼级层⾯来讲，这个查询想⼲的事情是什么。物理计划：它会去为我们指定我们之后执⾏查询计划时具体要使⽤的算法是什么。并传入到tree rewriter
5. tree rewriter：实际上，⼤部分的数据库系统都提供了Tree rewriter比SQL rewriter更常见，因为这是静态规则
6. 为了对抽象语法树进⾏重写，我们得去问System Catalog，我们的表⻓啥样，它⾥⾯有哪些属性，但这⾥我们不需要跑到成本模型（cost model）那⾥计算成本。接着，Tree Rewriter这边会⽣成和binder处所输出的相同的逻辑计划，然后将逻辑计划传入查询优化器
7. 查询优化器会⽤到System catalog所提供给我们的schema信息以及通过提供给我们的 成本模型来对这些⽅案进⾏成本估算；⼤型数据库系统内部会通过这个数据来对不同的查询计划进⾏⽐较，计算出来的东西只是一个指标。不能在不同的数据库系统之间比较成本模型 给出的数字
8. 所有的操作都是基于逻辑计划进⾏的，但最终还是需要变为⼀个物理计划的
#### 等价关系代数
1. 它的核⼼基础概念是让我们去对我们的查询计划进⾏操作和转换以此来找到更好的备选⽅案
2. 因为要记住关系代数或者关系模型是⽆序的，我不在意，这个查询所⽣成的tuple是这个顺序，另⼀个查询所⽣成的tuple是另⼀个顺序，它们的内容依然是等价的
3. 我们可以去使⽤关系代数中的传递性等特性，我们通过不同的⽅式来改变表达式的标准逻辑
4. 通过移动operator来⽣成更为⾼效的计划，我们将这种⾼级技术叫做查询重写
5. 我们往往会将更⼩的表作为outer table使⽤，因为这是我们通过成本模型得到的 结果，在不需要查看数据的情况下，我们就可以做到这种push down
##### 预测Pushdown
1. 你要去计算hash或者对某些东⻄进⾏加密,那么你可能会想将它放在上⾯。但数据库系统可以对此进⾏推理并判断它该处于哪个位置
##### 条件合并
1. `between 1 and 50 or between 50 and 150 `
2. 在这个MySQL版本中（5.7）,如果我试着插⼊⼀个null（主键那⼀列），它不会给我报错，相反，它会说：Oh，这是⼀个⾃ 增键.
3. 它就会继续执⾏这个SQL语句，并将这个null替换为下⼀个值，然⽽如果你这⾥插⼊null的话，其他系统就会给你报错
###### 为什么将⼀个复杂的条件进⾏拆分，要⽐直接对它进⾏操作来得更好
1. 如果其中⼀个判断条件的计算成本要⽐另⼀个来得更⾼；你可能会想将这个判断条件进⾏拆分并将它们放在查询计划的上层
###### 各数据库测试
1. `select * from actor where actor_id is null`
2. PostgreSQL执行了该语句，其他的并没有执行
3. `select * from film where film_id between 1 and 2 and film_id between 199 and 200`
4. PostgrepSQL执行了，实际上这是不可能执行的

###### 查询优化器是否能改变左边的部分
1. 可以
#### 预估计划成本 
1. 我们拿到⼀个查询计划，然后通过我们的成本模型来估计我们所需要做的⼯作量有多少
2. 当你在执⾏查询的时候，你需要使⽤多少DRAM，你的buffer pool得占⽤多少 内存空间，分布式系统还需要考虑消息的数量
3. 有⼀些数据库系统是没有成本模型和查询优化器的，它们实际上就会去执⾏所有不同的查询计划，然后看看哪个查询计划先返回结果。目前只有MongDB.所以当我得弄清楚使用哪个索引，那我就直接执行各种查询计划，谁先返回就用哪个，然后记住每次相同的查询
###### 这些查询是否是有序的执行
1. 我有⼀个需要在多个节点上执⾏的查询，它们拥有该数据的不同⽚段或者分区
2. 这些分区分属于表的不同部分，它们都有相同的很多索引（知秋注：要知道⼀张表可能会根据 不同的字段建不同的索引）
3. ⽐如对于这个分区，我会使⽤这个索引，那个分区，我使⽤那个索引，然后我会看看哪个执⾏地最快；然后，你就会看到相同的查询了
4. 你得将这个查询应⽤到所有不同的节点上，你只需选⽤相同的索引即可，因为这是对于所有⼈来说，最快的⽅法
##### 静态
1. 我们去预估执⾏查询的成本是通过在内部维护表相关的信息来做的
2. 当你调⽤Analyze函数时，这会触发⼀次循序扫描来查看数据，并更新这些内部的分布信息
3. 你可以在更新表的时候触发这个操作，或者把它作为⼀个⽇常任务，每天都执⾏⼀下，以此类推
4. 在System Catalog中，我们会去维护索引，表以及tuple中的值相关的元数据
#### cost-base search
1. 我们如何通过我们的成本模型来对查询计划进⾏成本估算,接着，我们会去讨论如何根据（逻辑）计划进⾏（执⾏计划）枚举。即我们实际该如何智能地列出所有不同的查询计划，以此来找到我们所认为的最佳⽅案
2. 本质上来讲，就是我们要去确定数据从⼀个operator传到下⼀个operator时，所传数据量的⼤ ⼩，我们可以根据它来推导出我们所认为的最佳⽅案
3. 在DBMS中，我们⽤来估算成本时所使⽤的基础组件就是DBMS内部的statistics catalog，每个数据库系统都有⼀个查询优化器。它们使⽤了cost-based search，它会有⼀个statistics模块。这允许我们去收集表相关的信息，即tuple中所保存内容的相关信息。我们收集信息的⽅式取决于DBMS中对此的具体实现。所有主流的数据库系统都会通过某种命令来强制收集新的统计信息
4. 某些系统会设置定时任务，它会经常定期去更新这些统计信息，其他系统可以在它们执⾏查询的时候，顺带更新这些统计信息。当我执⾏循序扫描的时候，我也会去更新我的statistics（统计信息）
5. 如果你运⾏的是⼀个OLTP系统，当你在执⾏事务的时候，⽩天你可能会将这个功能禁⽤
6. 对于每个logical tuple来说，我们会保存它的多个物理副本或者是多个物理版本号，我们没法去统计我们的block数量来作为我们的tuple数量
7. 实际上，我们想通过⼀个单独的count值来对它进⾏维护
##### derivable 静态模块
1. 我们可以⼀个新的数据信息，我们将它称为Selection Cardinality（选择基数），
2. 我们通过tuple数量除以属性A下去重后的值的数量来计算出选择基数
3. 我想知道该属性中每⼀个去重后的值所出现的次数，我拿到我们所拥有的tuple数量，然后除以我们所拥有的字段下去重后的值的出现次数
4. 该结果就会告诉我们它在每个属性中出现的次数
5. 当我们进⾏扫描的时候，我们要弄清楚我们能找到多少符合我 们条件的tuple，因为我们要弄清楚每个operator传给下⼀个operator的tuple数量有多少。那么，通过它，我们就可以知道它们实际的⼯作量有多少，要使⽤的磁盘空间有多少，以及内 存量有多少
6. 我们通过使⽤选择基数来计算children operator要提供给我们的数据量有多少
##### 复杂预测
1. 基于选择基数，我们就可以计算出单个条件的选择率（selectivity）了
###### 范围预测
1. `sel(A>=a) = (Amax - a)/ (Amax-Amin)`
2. 得出的结果是不对的，此时会造成与实际情况不符合，会导致因为上传多个元组造成一些问题
###### 非
1. `sel(not p) = 1 - sel(p)`
###### 交集
1. 例如：`age = 2 and name = "xxx"`
2. 会先计算每个的选择率，然后相乘即可
###### 无交集
1. `sel(p1 V p2) = sel(p1) + sel (p2) - sel(p1) *sel(p2)`
###### 解决heavy-hitter的方法是
1. 如果你有⼀些skewed（倾斜） data，它在10列中都有出现，或者说它出现了10次，它出现频率⾮常⾼。你可以通过维护⼀个单独的hash table或者直⽅图来跟踪这些东⻄。对于其他的数据来说，假设频率是统一的，可以根据频率来预测基数。用于解决均匀数据问题的手段
###### 相关属性
1. 假设`make = 'Honda' and model = "Accord"`
2. 生厂商和型号是相关的，因为只有这个生产商才会制造这个型号的车
3. 我们会开始⾃动估算，在执⾏我们的查询计划时，我们实际所做的⼯作量⼤⼩，并对我们的中间数据结构以及buffer进⾏调整。我们要进⾏权衡，对于独⽴性假设⽽⾔，这会让我们低估我们实际要做的⼯作量
4. 解决这个问题的⽅法：只有高端数据库才会做，即对相关列进⾏数据统计。我可以告诉数据库系统，model和make是相关的
##### 成本预估
1. heavy-hitter会去保存这些准确的值，但我们只可能会去保存每列中前10或者前20个不同的值。也就是直接在hashtable中直接存储这些数据
2. 解决方案：将这些数据划分到不同的桶中，⼀个bucket中我们只会保存⼀个值，我们不会为⼀个bucket中的每个元素都保存⼀个值
3. 等宽直方图：这⾥我们以每3个值为⼀组，然后计算这个bucket中每个值出现次数的总和。出现概率等于：count / 3，但往往出现偏差
4. 分位数：调整bucket中的宽带，使每个bucket的count总和都⼤致相等。我现在拥有不同宽度的bucket，但现在，我可以对这些bucket中每个值所出现的次数做出更为精准的预测
5. 当我们在我们的数据库系统中使⽤analyze或者stats时，它会为我们⽣成这种信息，并将这些信息保存在我们的catalog中，并且它会持久化到磁盘上
6. 我可以通过⼀个单独的后台线程来对这些东⻄进⾏处理，即查看⽇志中 最近的修改记录，然后对这些修改进⾏处理，但一般来讲会丢对然后重新计算
##### 样本
1. 在不使⽤这些额外数据结构的情况下，我们可以去维护⼀张样本表，然后根据该样本来衍⽣出统计信息
2. 从本质上来讲，直⽅图就像是数据库中表数据的⼀种低解析度副本，它是对其他内容的⼀种近似缩略表达
3. 随机取样复制元组到新的表，对表进行分析
4. 与其去维护这些可能不准确的直⽅图，我们只需维护这些样本即可，只有⾼端的数据库系统才会做这些事情
5. 诸如SQL server这些⾮常知名的数据库系统会做这种事情，并且它们的优化器可能是其 中最好的⼀种，但实际上，它们是将直⽅图和采样法结合在⼀起使⽤
6. 采样只对每个查询来说是准确的，⽤完你就可以丢掉了
##### 单一关系查询计划
###### 为什么只有⾼端的商⽤企业级数据库系统才会这样做，然⽽开源数据库系统 就不会这样做
1. 如果你已经调⽤了analyze,你会通过循序扫描来完成你的直⽅图,它可能会⽣成出这种东⻄。可鞥会发生直方图生成但是与答案不相符
2. 在我们的优化器中，我们会有这种成本模型，通过这些直⽅图，我们就可以快速知道成本
3. 因为我正在枚举所有可能不同的查询计划，我可以快速查看下我的直⽅图，以此来衍⽣出我预测某个条件或者operator的选择率所需的统计信息
4. 为了对选择率进⾏估算，我得对表进⾏循序扫描，在速度上，这肯定要⽐查看直⽅图来得慢
5. 如果我意识到我的查询很简单，那么直接使⽤直⽅图就可以了，如果我觉得这个查询涉及的⼯作量很⼤
#### 枚举计划
#### 嵌套子查询
##### 执行查询
1. explain analyze xxxx: postgrep
2. explain xxxx: mysql
3. explain plan  for : xxx