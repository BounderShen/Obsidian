##### 前言
1. 查询计划指的是指令，或者是数据库系统该如何执⾏⼀个给定查询的⽅式
##### 缓冲池
1. 当算法所需要使⽤的内存⽐实际可⽤内存来的更多的时候，我们就可以通过它来解决
2. 我们并不会将buffer pool管理器⽤在table或者索引上，⽽是⽤在中间结果这⽅⾯
3. OS会表示，这个page是⽤来保存临时数据的，⽤于执⾏我的查询，当查询结束了，我就⽴⻢将这个page给扔了。
#### Top-N deap sort
#### 外部归并排序
##### 有序
1. 如果我们的表是有序的，或者输出结果是有序的，或者key是有序的，那么我们就很容易去重
2. 现在只需要扫描一次表。如果现在看到的东西和之前看到的东西是一样的，那么我就知道这是重复的了，就可以扔掉
##### 对bulk进行优化
1. 当加载大量的数据时，对所有叶子节点进行预排序，自下而上构架索引
##### 为什么不适用快速排序
1. 快排会进⾏⼤量的随机跳转，它会随机跳转到内存中不同的位置上
2. 它所做的是随机I/O，因为我们所要跳转的page可能实际并不是放在内存中的
3. 在最糟糕的情况下，每对数据集进⾏⼀次修改，就要进⾏⼀次I/O
##### 两阶段
1. 尽可能最大化使用内存，并进行排序，然后将排序完的写回磁盘
2. 将这些合并为更大的runs，并写出，需要不断重复这个过程，直到排序完成为止
##### 2-way External merge sort
1. 需要知道我们可⽤的内存量有多少，以此将数据缓存在内存中，并对其进⾏排序
2. 如果所有东⻄都放在内存中的话,直接使用快速排序
3. 简单来讲就是，对于⼀个特定的查询来说，working memory就是它在进⾏中间操作时被允许 使⽤的内存量
###### 合并
1. 对于这种⽅法来说，我⾄少需要3个buffer page
2. 因为我需要⽤2个buffer page来保存我放⼊内存中的run，⼀个run对应⼀个buffer page
3. 然后，我需要另⼀个buffer page来保存我要写出的输出结果
4. 我只能对这些page中的数据进⾏扫描并⽐较，看看谁⽐谁⼤，或者谁⽐谁⼩，这取决于 你想要的是升序还是降序
5. page写满则写出到磁盘上，继续合并，使用两个游标来扫描这些page上的内容，并逐个比较
6. 引入其他数据集，并写出，直到扫描到page底部
##### 所展示的是什么
1. 可以看成元组
2. 实际中你所尝试⽤来进⾏排序的key，可以通过它来获取到对应tuple的record id
##### 双缓冲优化
1. 当你们要对其他两个page进⾏合并时，你通过使⽤shadow page或者shadow buffer来接收你所要排序的下⼀个run或者是page
2. 它需要让你减少异步I/O的数量，以此在后台取获取我们接下来需要的page
##### 假设这些排序操作是在内存中操作的
1. 第一轮是，接下来就不是
2. 教科书中的做法
##### 在内存中操作
1. 这取决于你们从哪里读取数据
2. 如果来源于表自身，那么就无法修改，来自其他操作可以直接修改
##### 优化
1. 当一个块的最大值小于另一个的最小值可以直接合并，但需要额外的开销
##### 聚簇索引对排序的意义
1. page中tuple的物理位置和我们在索引中定义的顺序相匹配
2. 如果我在key foo上有⼀个索引，那么我们会根据foo在索引中的顺序来对page中对应的tuple进⾏排序
3. 如果我现在想根据这个key来进⾏排序，我不需要去使⽤external merge sort
4. 因为现在根据该key所得到的顺序会匹配数据在B+ tree中所找到的顺序，我不需要通过任何额外的计算来进⾏排序，因为它已经为我排好了序
5. 查询优化器可以帮我们弄清楚这⼀点，⽐如，如果我们想基于这个key进⾏排序，它表示，我 已经有了关于这个key的聚簇索引，它就会去使⽤这个聚簇索引来⽣成正确的排序顺序，⽽不是再去执⾏external merge sort
6. 但在PostgreSQL中，它们并不会强制使⽤这个。你想要这个给定key所在的对应聚簇B+ tree索引所指定的节点，PostgreSQL不会去维护这⾥⾯的排序顺序（知秋注：即并不会对节点内tuple进⾏排序）
##### 非聚簇索引
1. 即叶⼦节点不保存整条tuple 数据，只保存索引对应字段数据）
2. 对每个记录，你都得进⾏⼀次I/O操作
3. 我会从树的左边开始遍历索引，然后跨叶⼦节点进⾏扫描。因为这是我key的排序⽅式
4. 但我所需求数据的顺序与索引中数据排列的顺序并没有什么关系。我要去获取每个record，并⽤它们⽣成输出
##### 树中的信息是什么样的
1. 我们在key foo上创建索引，为了构建索引，我要进⾏循序扫描，以此得到每个tuple中key foo上的值，然后将它们 插⼊我的tree中
2. 这⾥的key/value pair就是foo的值
3. 这⾥的value是这个record id所指向的tuple
#### 聚合
1. 不管磁盘的速度有多快，通常情况下hashing这种⽅式的效果会更好
2. 过滤、去除不需要的、排序、去重

##### 分区、重新哈希
1. 所有相同的key都会在同⼀个分区（知秋注：这个分区⾥包含的key可能会有所不 同，但相同的key铁定在这同⼀个分区⾥，这⾥的⼀个分区⾥只有这⼀种key）
2. ⼀旦我们扫描该分区内的所有page时，我们会去计算我们想要的答案
3. 然后我们可以将这个hash table扔掉，因为我们知道它已经⽣成了⼀个结果
4. 因为我们在该分区所更新过的key，永远不会在其他分区中被更新了。因为hash处理为我们保证了局部
##### 当hashtable中的内容写入最终结果时，为什么需要这个
1. 当你处理完数据，那么你就将处理完的数据塞进最终结果就⾏
2. 对于DISTINCT来说，这很蠢，⽽且没有意义。对于聚合操作来说，你也可以那么做
3. 最终结果会因为内存不够
##### 当在哈希表中是使用了哈希种子，在分区的时候可以换个hash seed吗
1. 不是很重要。但如果需要写入到同一个hash table 中就需要相同的seed
2. 打算合并就不需要
##### 真实场景
1. 例如求平均值：将key映射到对应的元组上，统计相同key的数量，接着求总和，拿到value计算出最终结果，使用Running_Total除以个数
2. ⼀般来讲，就是去跟踪单个标量值，每当遇⻅⼀个新的具有相同值的key（单纯指key），就加 1
3. 当我们想去更新hash table时，在我们进⾏插⼊的时候，如果hash table中没有，那我们就将数据加进去，那么我们就需要能够去修改这个地⽅的值
4.               
