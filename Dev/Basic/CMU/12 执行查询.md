### 执行查询一
#### 处理模型
##### 循环模型
1. 层层调用子节点的next函数返回
2. 在⼀个查询计划中，我们对⼀个给定的tuple进⾏⼀系列处理加⼯的过程，我们将它叫做 pipeline
3. Join操作中使用hash Join，此次会构建hashtable并且在probe阶段进行检测
4. 当构建完了hashtable，就代表处理完了所有元组，传入一个空指针告诉父节点不需要调用了
5. 一系列对单个元组处理进行处理称为流水线
6. 大部分数据库都使用此模型
7. 管道破坏者：Order Byy或⼦查询等这些需要你去获取更多tuple的操作的时候，这是不可避免的
##### materialization模型
1. 基于迭代模型的特定版本，主要用于内存模型
2. 返回的是缓冲输出包含了所有的元组
3. 对于OLTP workload来说，materialization model⾮常棒
4. 在OLTP workload中，我们所要做的就是⼀次获取⼀个记录，或者⼀次获取少量记录
###### 问题
1. 放在内存中，那么函数会有些问题
2. CPU上有latch，代价会很高。它会去跳到硬盘上写数据（知秋注：这样的话，这些函数的阻塞时间会很⻓，也就会阻塞 CPU，如果我们⼀次处理很多数据的话，那如果有跨事务的数据，产⽣死锁也不⼀定，所以， 数据的范围，即数据量越⼩越好）
3. 在使⽤materialization model的情况下，如果我们每次只向上传⼀个tuple，那么没⼈在 意这种开销。这样做很棒，速度超快
##### Vectorized
1. 每一次调用next拿到的是一堆元组
2. 对于每次调⽤Next时所返回的tuple数量来说，这取决于我们的硬件。这取决于存储设备，⽐如它的速度有多快，它做的是不是循序I/O
3. 在现代的CPU中有⼀些指令，它们允许我们⼀次对⼀堆数据进⾏多个操作，called : simd。有一堆数据，这堆数据能放⼊你的CPU寄存器中，通过这种单条指令，你可以很有效率地对这些数据进⾏条件判断或者计算
4. 接着当我们向下⾛的时候，我们要去检查，output buffer的⼤⼩是否⽐我们想发送的数据量 更⼤。足够大则可以发送
5. ⼀旦我们拿到了这个批处理后所得到的所有数据，那么我们将它向上传递，并对它进⾏处理
6. 因为分析型查询所做的是⻓时间对很多个表中⼤部分数据进⾏扫描
7. 这⼀批tuple的⼤⼩取决于数据的来源，以及你要如何处理它
##### 模型计划
1. 自顶向下
2. 自底向上
	1. 当我们向上传递数据的时候，我们得确保我们所正在处理的数据能够放在CPU缓存和寄存器中
	2. 如果你对内存位置和内存分配的操作⾜够地细致⼊微，那么这种⽅式更为合适
	3. 但这是在所有数据都放在内存中的情况下
#### 访问方法
1. 可以根据索引来读取数据或者对表进⾏循序扫描来获取数据
2. 索引可能不会⼀直有（知秋注：可能没有某些字段创建索引），但基于我们所做的查询，索引 这种⽅案会来得更好
3. 我们的备胎选项始终是循序扫描
4. 多索引：单索引允许我们通过⼀个索引来访问数据，我们也可以通过多索引来访问数据，并将结果合并在⼀起。
5. operator得去维护迭代器结束时的状态（知秋注：即每⼀次返回时，那个tuple所在的位 置）
##### 顺序扫描优化
###### 预抓取
1. 我们会⽤两个buffer来进⾏join操作（知秋注：⽽不是⼀次只读⼀条tuple来进⾏操作）
###### 缓冲池略过
1. 我们使⽤⼀个⼩buffer来对我们的线程或者查询进⾏缓存，⽽不是去污染我们的buffer pool缓 存

###### Zone Maps

1. 提前计算一些聚合的信息例如平均数、或者衍生出一些额外的元数据，它会为我们提供该page中给定属性的相关值的信息
2. 有些系统会将Zone Maps保存在该page中，还是需要读取到内存上，但至少不需要遍历
3. 其他系统可能保存在单独的Page中。，我会有⼀个专⻔的Zone map block或者Zone page，上⾯保存了不同page的Zone Map。，我会有⼀个专⻔的Zone map block或者Zone page，上⾯保存了不同page的Zone Map。
4. 接着，我就跳到这个page，然后检查下Zone Maps中的信息。接着，通过它来判断我是否该去下⼀个page或访问这个page
5. 每当更新时确保元数据同步更新，避免假阴性。所以这个适合在OLAP场景使用

##### late materialization

1. SIMD会将这些offset值或者column id传给我们，并允许我们稍后去获取我们所需的数据
2. 列式存储中，我们得做一堆不同的读操作，因为数据被拆散到不同的列中去了，所以需要尽可能推迟这些读操作
3. 我们可以智能地识别出在处理该查询计划时，它不同部分我们所需要传⼊的数据
4. 然后，我们只需要传⼊offset值，这允许我们之后回过头去获取我们所需要的剩余数据

##### 索引扫描

1. 识别表中有哪些索引，以便能快速找到我们所需要的数据，并限制做无用功
2. 减少数据处理过程中不必要的筛选
3. 索引选择取决：取决于我们是在哪些属性上建⽴索引、我们在我们的查询中⽤到了哪些属性、会取决于这些属性值实际是什么、对于我们的查询来说，它们是否具备选择性、也取决于我们使⽤什么样的索引

##### 多索引扫描

1. 多索引扫描（multi-index scan）指的是通过不同的索引进⾏多次查找
2. 基于我们的判断条件，我们将它们的结果进⾏合并
3. 

###### 索引并不是都比循序好

1. 当大部分都符合条件，循序比索引要好

1. 我就会想使⽤这两个索引进⾏索引扫描，并获取它们的结果，然后基于查询实际所要做的事情，我们通过某种⽅式将它们的结果合并在⼀起。接着通过这个结果来找到实际匹配的数据或者我要查找的数据

###### 多次扫描

1. 这取决于条件判断，如果是in⼦句，那就对索引进⾏多次探测
2. 如果它是范围⼦句之类的东⻄，那么我们就可以沿着叶⼦节点进⾏范围扫描

##### 索引扫描页面排序

1. 使用非聚簇索引我只需沿着叶⼦节点扫描就⾏，我会随机跳到不同page上的不同record id上
2. 因为这些tuple所排列的⽅式和索引中叶⼦节点所排列的⽅式并不相同
3. 糟糕情况，当只有一个缓冲页面，所查看的页面和上一次不同就需要对磁盘进行一次IO

##### 基于我的查询

1. 在我对数据进⾏任何查找之前，我会沿着叶⼦节点进⾏扫描，并获取所有record id，然后，我根据page id对它们进⾏排序
2. 对于每个组中的每个page来说，我们需要通过⼀次IO来获取⼀个page，在我处理下⼀个page前，我会处理完当前page中的所有tuple

##### 排完序后

1. 假设我需要page 101中的两个tuple
2. 我知道它们在哪个page，它们在page 101，我知道它们的slot号。当我拿到这个page，我跳转到slot 1，然后，跳转到slot 5，这样就找到了我想要的元组并不需要进行遍历

##### 实际该如何维护聚簇索引

1. 页满了，接着往里面插入一个东西，意味着我需要重新洗牌
2. 除⾮你将所有东⻄保存在MySQL或者InnoDB中，它们的叶⼦节点上实际保存的就是这些tuple
3. 当我们对⼀些合并的page进⾏拆分时，那我们就要将这些key/value从⼀个page移动到另⼀个page
4. 如果这是⼀个聚簇索引，此时，它们便⽆法准确地和底层的data page连接起来（知秋注：如 果在索引叶⼦结点中间做个插⼊的话，会引发⻚分裂，聚簇索引依赖主键来做快速地顺序插 ⼊，但⼀旦中间插⼊，那整个主键就乱了套了，树的中间节点都会发⽣改变，也就⽆法准确定 位某些叶⼦节点了）。没错需要做很多额外的工作
5. 这也是为什么大多数的数据库没有将聚簇索引作为默认索引的原因

##### 解释关于pipeline  breaker

1. 局部性的结果不会导致最终不一样即可
2. 因为Order by上面的查询部分对一部分进行处理，但是这只是部分的结果，类似归并排序。需要对这个查询的结果进行归并才能得到一个排序的。
3. 从局部看整体，整体看局部即可

##### 表达式评估

1. 简化条件判断：1 = 1 ；这是只有高端数据库才做的事情，mysql没有

### 执行查询2

#### 前言

##### 为什么关系使用并行计算

1. 获得更高的吞吐量，查询速度，处理更多的任务，更低的延迟
2. 这会减少我们数据库系统⾃身的总成本（TCO）用于的在企业中考虑数据库成本方面的术语

#### 进程模型

1. ​	DBMS中的进程模，型其实就是我们如何组织系统来通过多个worker来处理并发请求的⽅ 式

##### 每个进程就是一个工人

1. 每个进程都有自已的缓冲池，并将页面放入到内存中
2. 可以使用共享内存，它可以允许这些不同的进程在内存中通常具有各⾃独⽴的地址空间

##### 进程池

1. 不会为每个连接去创建进程而是放了一堆线程，从中选一个即可
2. OS负责进行调度，可以设置进程的优先级

###### 是否有多个进程池

1. 只有一个，但是进程的数量是不固定的，也就是说我可以在启动的时候进行设置进程的数量
2. 进程池中有一个管理员，可以做些特殊的任务，可以拿到来自管理员账户所传入的请求



1. 能够意识到一些情况并对该情况会提供一些解决方案，比如这个处理数据太长了，派一个人去帮忙它
2. 高端数据库可以做到这点。IBM和PostgreSQL2015使用了这种方案，

##### 一个线程一个工人

1. 现在大部分系统都是使用多线程
2. 使用一个进程去运行，并根据需要去对任务进行调度
3. 这种情况下，我们完全占据了主导权，我们知道这些任务是什么，我们也知道我们能使 ⽤哪些线程
4. 因为这⾥我们要去使⽤多线程进程模型这种⽅案，这并不意味着，我们能够⾃动并⾏执⾏查询。我们可能也不⼀定要做到intra-query parallelism
5. 这意味着它并不保证我们DBMS内部的任务⼀定可以使⽤多线程来处理，如果我让它去执⾏⼀个查询，它⽆法将这个查询进⾏拆分来让多个线程并⾏执⾏这些任务。MySQL 5.7是⼀个多线程数据库系统，但它没法做到intra-query parallelism

##### 调度

###### 对于⼀个给定的线程来说，OS会去决定⽤哪个core来运⾏它吗？

并不是这样，在Linux的错误测试集中，这叫做Neumann control，你可以让你的线程在这个core或者这些core上运⾏，它的控制权完全在你⼿上。OS不会为你强制做这些，如果你什么也不做。那么OS可能会去这么做，举个例⼦来说，当你访问内存的时候，如果OS提供了2个CPUsocket供你使⽤。在现代的众多系统中，⼀个CPU socket中有它⾃⼰的本地内存，即和它邻近的DIMM存储模块(知秋注:就是内存插槽上的内存)。如果你的线程是在这个Core上运⾏，并且你正在访问另⼀个CPU socket上的内存。OS或者CPU会⾃动将你迁移到那个CPU core上⾯去。但在⾼端的数据库系统中，我们能够准确地知道我们所接触的数据有哪些。我们可以提前强制让这个任务所在的线程在这个Core上执⾏，它只能从这块内存区域上读取 数据。所有任务所涉及到的内存都在这块内存区域上，我们可以⾃⼰来调度这些任务

1. Dispatcher或Coordinator能够知道我需要执⾏的任务有哪些，哪些资源或worker对我是可⽤ 的，然后，它就可以去决定该将⼀个查询拆分成多少，个任务，它可以去决定使⽤哪个CPU core来执⾏这些任务，哪条线程要等其他相关线程执⾏完后再继 续往前执⾏，接着，⼀旦某⼀个线程所执⾏的任务⽣成了结果，那么该输出结果该往哪⾥放呢。
2. 方法好不好取决于工作环境，想要支持的workload类型

##### inter VS intra Query

1. inter: 我们可以在同⼀时间执⾏多个做不同事情的查询，就是多线程处理多个请求
2. intra：对于intra-query parallelism来说，它是将⼀个查询拆分为多个⼦任务或者⽚段，然后 在不同的资源上同时并⾏执⾏这些任务。用于分析性

##### intra 并行操作

1. 我们将⼀个完整的操作拆分为多个平⾏的操作，即我 们将操作的数据分为多段（fragments），每⼀段执⾏的函数都是⼀样的
2. 我们会对每个fragment执⾏相同的操作，这⾥的fragment中的数据属于我们所输⼊数据的⼀ 部分
3. 如果我要对⼀张表进⾏扫描，我可以去使⽤该scan operator的多个实例，我们会使⽤不同的线程来对不同的fragment进⾏相同的处理，每条线程都会去扫描表中的不同部分，它们会将数据收集在⼀起（是如何进行拆分的）
4. 这⾥我们使⽤⼀个叫做exchange的operator来将这些结果组合在⼀起，exchange operator会放在查询计划中的某个位置
5. DBMS会对此进⾏⼈为⼲预，当它⽣成了查询计划，它会说：All right，在这些地⽅，我可以对这些fragment进⾏并⾏处理，我会去放⼀个exchange operator，它能够将我们处理完的fragment的结果结合在⼀起

###### exchange  operator在这里是如何调用next函数的

1. 以并行的方式调用这些函数

###### 如果我调用这里的next一次，它是怎么传给其他人呢

1. 在上面放置一个协调者，并说，我知道我需要从这⼏个fragment中获取数据，我会⼀直调⽤Next，直到它们没有数据 可以⽣成为⽌

###### 如何确保读的不是同一个Page

1. 你会说，这⾥有⼀堆任务需要去做，第⼀条和第⼆条线程已经获取完它们之前所负责的那些page了。
2. 它们会说，让我去队列中获取下⼀个我要读取的page，你会⼀直持续这样做下去，直到你读取完所有的page中的数据，然后，你就会停下来

###### 保证顺序

1. 一般情况下是不会去保证顺序的，如果你对顺序很在意的话，你可以在你的表上使⽤聚簇索引
2. 如果你处理数据的顺序很重要的话，那么你就不会选择去并⾏执⾏你的查询

##### exchange operator

1. Gather：我们将不同的worker线程执⾏任务所得到的结果，或者是这些operator所⽣ 成的不同输出进⾏合并
2. 分区：我根据值域来对数据进⾏划分，这样我就我可以进⾏并⾏扫描，然后，将它们放进repartition exchange operator中进⾏处理
3. 分布式：们从我们的表中获取⼀个单个输⼊流，然后，构建hash table，接着，将不同层的hash bucket交由不同的线程进⾏处理
4. Oracle，DB2和PostgreSQL所有这些⾼端系统都⽀持并⾏执⾏
5. 执⾏这些operator操作的线程都在⾃旋等待数据的传⼊。
###### 复杂例子
1. 将表中的数据分成段，并由三个线程去执行，每个线程维护一个hashtable
2. 并由exchange operator进行将结果组合起来
###### 协调员
1. 最关心自旋锁等待数据
2. 因为如果⽣成的tuple数量很多，那么速度就会很慢。如果对同一个数组有读写就会造成阻塞
3. 可以将两个操作一起使用，垂直和水平一起
4. 在Join操作中水平并行，通过垂直并行将这个projection操作整合在一起
##### bushy 并行
1. 我们让不同的worker在同⼀时刻对⼀个查询计划的不同部分进⾏操作,这⾥我们依然使⽤exchange operator来在这些operator之间移动数据
###### 这⾥的worker 3和4是否停在那⾥等待worker 1和2所处理的结果，在这个例⼦中，是这样的
1. 这取决于exchange operator是如何设置的
2. Join操作后，下面的Worker得到的结果会上传到operator中
3. 它可以使用tuple来构建hashtable，可以进行等待也可以不进行等待，取决于operator怎么设置
###### 同一时间只有一条线程可以去更新hashtable
1. 因为这些线程访问的是不同page，我可以去并⾏执⾏这些任务
2. 我们可以对这个hash table中的每个分区进⾏并⾏更新（知秋注：如果说两条线程更新的 都是同⼀个分区，那么它会阻塞，类似于JDK中ConcurrentHashMap的分段锁）
3. hashtable中内容是什么？是否需要加锁机制才能保证其？为什么要建立hashtable
###### 依然在访问同⼀个hash table
1. 在第⼀轮中，我们通过不同的线程去对不同的bucket进⾏更新
2. 但当你进⾏hash处理的时候，你最终可能会将两条线程hash到同⼀个bucket中
3. 那么你就得去处理这种情况，这种情况是我们⽆法避免的
4. 或者在⼀轮中，你可以先让⼀条线程去构建出hash bucket，然后你再去并⾏执⾏任务
5. 假设如果你的磁盘速度超级慢，并且你的数据也没法全部放在内存中，那么使⽤单线程来构建hash table并对其进⾏扫描这种⽅式可能会更好。因为通过这种⽅式，在我们循序扫描时，我们⼀次能够尽可能多的获取数据
6. 如果使⽤的是SSD，那么你就可以同时处理多个请求，那么你就可以并⾏构建hash table了
###### inter-operator和bushy之间有啥区别
1. 因为我对左边两张表进⾏join操作，然后我⼜对右边两张表进⾏join操作，我可以使⽤⼀条线程来负责左边的join操作，另⼀条线程负责右边的join操作。在这两者之间我不需要使⽤coordinator
2. 直到进⼊了exchange operator后，我们才需要使⽤coordinator
3. 在这种策略中你会看到，每个operator就是它⾃⼰的worker，⽐如，Spark，Streaming，Apache Hive，Flink，Storm，或Kafka这些系统通常使⽤的都是 这种架构
###### 对于此处的这个exchange operator来说，它既可以将数据传递给这个operator，也可以传给另⼀个operator，我该如何选择呢？
1. 这也是我们纳⼊查询计划中的⼀部分，这⾥我想基于我数据库表中这个属性来对数据进⾏分区，我想通过round-robin或者 hash处理来进⾏判断，即该将数据传给哪个operator
2. 这⾥会存在着某种逻辑，它能够帮你判断该如何处理数据
3. 你不会想去使⽤round-robin,因为你需要知道左侧这边的tuple如果和右侧的tuple匹配上了，你就会想让它们都去⼀个分区⾥呆着，⽽不是不同分区。如果我的数据落地到不同的分区，这可能就会造成假阴性的效果
###### 高级层面
1. 每个数据库系统都以不同的⽅式⽀持并⾏查询，它们都会⽀持某种形式的exchange operator，它们的复杂程度取决于系统的复杂程度
#### IO并行
1. multiple disks per database
2. one database per disk
3. one relation per disk
4. split relation across multiple disk
##### 多磁盘并行
1. 对系统进⾏配置，我们让多个存储设备以单个逻辑设备的形式来供数据库系统使用
2. Linux的内核就⽀持对RAID进⾏配置，或者我们可以使⽤存储设备，它可以为我们提供这种功能
3. 在⼤多数情况下，对于RAID设置来说，它和数据库系统是完全独⽴的。这些是由数据库系统所管理的东⻄，它就可以很智能地做出决策，即该如何执⾏它的查询计划
4. 因为它知道数据是如何排列在不同的设备上的，并且它也知道这些设备的速度是多少
5. 数据分条技术：创建Page,并写入数据时，存在RAID控制器，它会根据Round-Robin策略来决定你该往哪个存储设备上写数据，在它内部有⼀个元数据，它会说：Oh，我需要page 1，我知道它在这个磁盘上，那我去拿到 这个page。数据库系统并不知道
6. 另⼀种常⻅的做法就是Mirroring（磁盘镜像），简单来讲，每个存储设备上⾯都会保存⼀份该page的副本
8. 你可以通过某种纠错码或者其他⽅法来确保在⼀个磁盘挂掉的情况下，你可以通过它从其他磁 盘上保存的page来重新创建该page
###### RAID1的速度是不是有点慢，对于数据写入是这样的，数据读取快
1. 我可以从其中任意⼀个磁盘上读取数据，我可以让⼀个线程去读取page 1，另⼀个线程去读取page 2，它们可以通过不同的设备上进 ⾏读取，这样是ok的
2. 写入数据来说，我得确保这些写⼊的数据传播到所有的磁盘上，这就使得写⼊的代价很昂贵了
##### 数据库分区
1. 思路：数据库中的数据拆分为不相交的⼦集，然后将它们分配给离散的磁盘
2. DBMS buffer pool管理器知道，如果我需要去读取⼀个page,它知道我们所查找的那个数据是存放在哪个分区或者磁盘位置上的
3. 分区方法：如果你的数据库系统⽀持的话，你知道的，⽐如⼀个⽂件就是⼀个数据库，或者⼀个⽬录就是⼀个数据库
4. 你可以设置软链接或者硬链接，来让这些不同的⽬录指向不同的磁盘
5. 这个⾼端数据库系统就像是⼀个数据中⼼管理员，它可以根据软链接或者硬链接来将数据分配 到不同的磁盘上
6. log⽂件上保存的是我们对记录所做的所有修改,通常情况下，log⽇志这种东⻄是需要被存放在中央位置的
7. 但如果你有多个不同的存储设备,那么就需要对log⽂件进⾏分⽚
##### 分区
1. 分区的思想在于，我们想去拿到⼀张单个逻辑表，并将该表中的数据拆分为不相交的⼦ 集，然后，我们将这些⼦集分别存放在不同的存储设备上，并对它们进⾏管理
2. 水平分区：将表中的数据进行分半；垂直分区：根据属性进行分区
3. 有些数据库支持垂直分区，它们所使⽤的是⼀种类似于列式存储的⽅式，但并不相同他们并不会对此进行优化
###### 列式存储和垂直分区有什么联系
1. 可以在列式存储中做到垂直分区，从高级层面是一回事
2. 在行式存储数据库系统中进行垂直分区，但当处理查询时，对于列式存储并不高效，可能你使⽤的依然是iterator model，⼀次只获取⼀个tuple。或者，你不⽤去压缩数据
##### 垂直分区
###### 如何对表进行分区
1. 你知道的，我想通过属性attr4来进⾏分区，我知道attr4在每个tuple中offset值的位置
2. 我知道该如何对表进⾏拆分，然后将这部分移动到这个分区中
3. 我知道如何根据offset值来跳转到tuple 1内部中的位置，对其他tuple也是⼀样的
###### 分区是由用户定义的还是数据库系统为我们自动做的
1. 用户定义的，但⾼端的数据库系统都会为我们提供⼯具来帮我们做到这点
2. 
