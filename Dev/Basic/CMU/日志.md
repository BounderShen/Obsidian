#### 故障分类
##### 事务故障
1. 逻辑错误指的是事务试着去违反某些内部完整性约束
2. 内部状态错误：当事务遇上死锁，或者事务试着去更新我们所不允许更新的东⻄，如果遇上这些问题，我们不会允许事务继续执⾏下去。你要确保，当经历了⼀次崩溃后，它们不会被持久化
3. 
##### 系统故障
##### 软件故障
1. 系统本身出问题，数据库系统中有⼀些糟糕的代码（1/0）。导致系统发生崩溃、中止。我们需要能够在我们的数据库系统中处理这些故障，并确保任何正在执⾏的事务会被中⽌并被正确回滚，或者确保在这个错误发⽣之前，它们所提交的所有修改都已经被持久化了
##### 硬件故障
1. 运⾏着我们数据库系统的那台机器发⽣了崩溃或者停⽌⼯作
2. 我们假设，如果我们遇上了硬件故障，我们始终可以让系统恢复正常，并让数据库恢复正确的状态
##### 存储故障
1. ⼀种不可恢复的硬件故障指的是诸如盘针损坏盘⽚，或者是机器着⽕烧化磁盘之类的情 况
2. 没有任何数据库系统可以从这种情况下恢复过来
##### undo VS REDO
1. 简单来讲，我们要去维护⼀些信息，这些信息可以让我们去恢复事务对数据库中某个对象所做 的任何修改
2. 我们需要去维护与Redo相关的信息，通过这些信息我们会重新执⾏某个事务对数据库中的某 个对象所做的修改
3. 如果我需要回头进行修改，就需要通过redo这些信息来告诉我该如何做
4. 基于这两个原则我可以构建更复杂的东西，logging协议允许我们在正确的时间生成这些信息，经历了崩溃之后，会以正确的方式让我们恢复数据库
5. 如果使用两个原则：取决于我们如何管理缓冲池中的dirty page
##### 缓冲池
1. 在我们允许事务被提交前，我们是否应当强制让这些事务将与它有关的所有dirty page都落地 到磁盘上
2. 在⼀个事务还未提交的情况下，我们是否能够复制⼀个page或者从buffer pool中移除⼀ 个page
##### steal 策略
1. 在事务被允许提交前，数据库系统是否允许⼀个未提交的事务覆盖掉数据库中某个对象最近被 提交的值，并将修改落地到磁盘上
2. 思路：如果我所执⾏的某个事务耗尽了我buffer pool中的空间，该事务是否允许从另⼀个未提交事务⼿上偷取buffer pool中的⼀个page或者slot呢？
##### force 策略
1. 在我们允许该事务提交前，DBMS是否要求该事务所做的所有更新都先落地到磁盘上
2. Force策略让我们处理起来更加容易，因为这允许我们能够更快地恢复数据库中的内容，因为当DBMS恢复正常的时候，我们能够看到磁盘上DBMS发⽣崩溃前我们所做的所有修改
##### no steal + force
1. no steal ：任何未提交事务所做的修改都⽆法落地到磁盘
2. force ：在该事务被允许提交前，它所做的所有修改都必须落地到磁盘
##### 当t1进行修改，t2进行修改并提交
1. 将page复制到内存中，我们只去提交我们想做的修改，或者是撤销那些我们不想要的那些修改
2. 接着将page写出该到磁盘上，
3. 对于buffer pool管理器和⼀个⾯向磁盘的数据库管理系统来说，No Steal+Force是实现可恢 复的正确持久化最简单的⽅式
4. 因为当系统经历崩溃后，我⽆须做任何Redo操作，当系统恢复正常后，我的数据库会保证它处于正确的状态；在运⾏时，我从来都不需要去撤销⼀个中⽌事务所做的任何修改；因为这些被中⽌的事务所做的修改并没有落地到磁盘上
##### 问题
1. 对一个页面需要多次的写入，如果是固态硬盘会导致寿命急剧减少

#### 影子页面
1. no-steal+force，存在这大量的随机IO但是能保证正确性
2. 就是将那些未提交事务所做的修改保存到⼀个临时空间中，接着，在某个时候，当这些事务提交了，你会以某种⽅式来解析⽬录或者page table并表示最新版本。遇上崩溃，只需要忽略掉临时buffer中所做的修改
3. 当一个事务提交的时候，希望以原子方式将Shadow page变成新的master副本。我们可以以某种方式做到这一点，如果我们对多个page进⾏更新，我们就⽆须去关⼼更新撕裂的问题
4. 思路：你可以将你的page⽬录组织为⼀个树形结构，现在你只需要去复制这棵树的⼀部分数据，然后对该副本数据进⾏更新，这样也就⽆须再重新创建⼀个完整的hashtable。这棵树的根节点其实是数据库的根节点，它指向的始终是最新的master版本数据
5. 这意味着我们可以对树的较低部分处执⾏⼀系列修改，我们要更新叶⼦结点，并让它指向我们刚刚创建的新page。当我们准备好对这些page进⾏原⼦修改，我们只需将database的root指针指向该树的shadow部分即可，那么我们所做的这些修改就会⽴即可⽤
6. 

![[shadow.png]]
![[shadowPage.png]]
1. 任何只读型事务都可以跑到database root这⾥，并查看master page table，然后读取到⼀致的版本数据
2. 但如果我们有⼀个要执⾏更新操作的事务，我们必须创建⼀个shadow page table，事务会在这⾥⾯对page进⾏修改
3. shadow page table指向的page与master page table指向的page相同
4. 当现在这个事务开始修改这些page时，我们会将要修改的这个page的副本复制到磁盘上临时空间中的⼀个新位置，并在那⾥执⾏我们的修改
5. 接着，当这个事务表示：我想进⾏提交了，我们所需要做的就是，更新这个database root，它是保存在⼀个单独page上的，让这个database root指向这个shadow page table的某⼀部分
6. 我们将我们做的修改落地到磁盘，⼀旦我们所做的修改持久化到磁盘后，就更新下内存中的指针，然后所有的人都可以沿着指针找到这个page
7. 不管哪个事务被提交了，page刷入磁盘，会携带着一些时间戳或者事务之类的信息
8. 如果你假设T1和T2都是在同⼀批次中进⾏提交的话，这就需要在这个case（例⼦）中对它们进⾏处理，因为在内存中我拥有我⽤来撤销事务所做修改时所需要的Undo信息，只要这些数据被写出到磁盘，那么，我可以在shadow page table中撤销这些修改
![[shadowPageCommit.png]]
#### write-ahead log
1. 我们会在⾮易失性存储设备上维护⼀份单独的⽇志⽂件，以及我们的table heap，当事务对数据库进⾏了修改，我们就会在该⽇志⽂件的条⽬中记录下这些修改。当事务提交的时候，我们仅需保证我们将它们所⽣成的⽇志记录落地到了磁盘上
2. 使用steal+no - force：因为在事务被实际提交前，只要这些事务所对应的⽇志记录先落地到磁盘，那么我们能够将这 些dirty page写出到磁盘；我们不要求事务对这些对象所做的所有修改都落地到磁盘，我们只要求这些⽇志记录被写⼊到磁盘
3. 直到我们所有的⽇志记录被落地到磁盘，我们才会去考虑事务提交，协议在这⽅⾯并不奏效
##### WAL 协议
1. 事务开启时在日志中写入Begin记录表示这个事务开始了，这是关于这个事务的一些元数据，这是它的标识符。当事务提交的时候，在日志中写入一个commit记录，你要确保该COMMIT记录出现在⽇志中的位置是在该事务所做修改的对应⽇志记录的最后，它可能会和其他事务所做的其他修改交织在⼀起。但对于我们此时关⼼的这个事务来说，我们的COMMIT记录需要出现在该事务所做修改操作 的最后。日志中一旦出现commit我们知道这个事务无法做其他修改了
2. 需要记录：事务ID，修改对象ID，before value (undo)时使用，after value（Redo）。这些信息⾜以让我们能够恢复数据库，并处理我们在⼀开始所提到的各种可能故障
##### WAL example
1. 事务执行的时候，我们会往我们的⽇志记录中添加⼀个新的条⽬，并表示这⾥有⼀个刚开始执⾏的事务，当你调⽤BEGIN的时候，通常该事务还并没有完成，除⾮你调⽤COMMIT，该事务才会完成。通常它在第⼀个写操作的时候，就完成了
2. 现在我执⾏W(A)，我⾸先需要做的事情就是往我的WAL Buffer中添加条⽬，该条⽬表示，这是我对A所做的修改，这⾥是Before Value，那⾥是After Value
3. ⼀旦这条记录出现在我的WAL Buffer中，我就会对我buffer pool中的page进⾏修改
4. 我们先将⽇志写⼊WAL Buffer⽽不是先修改buffer pool中page数据的原因是，因为这⾥⾯有⼀个叫做⽇志序列号的东⻄，我们会将它分配给⽇志记录，我们需要通过⽇志序列号来弄清楚是哪个⽇志条⽬对这个page进⾏了修改
5. 当我进⾏提交的时候，我会将我的COMMIT记录添加到WAL Buffer中
6. 接着，在某⼀时刻，我会将WAL Buffer中的⽇志记录落地到磁盘。因为我们需要告诉外界这个事务已经被提交了，我们会⽴即调⽤FSync命令将这份⽇志刷出，⼀旦磁盘告诉我们，该⽇志已经被持久化了
##### 为什么我将WAL Buffer中的数据保存在某个page内，⽽不是将它作为⼀个单独的⽂件保存呢
1. 在日志结构存储中没有这种page，如果你不使⽤这种⽅案（放弃使⽤page），那么，这会让你的读操作成本变得很⾼
2. 因为当每次读取数据的时候，你必须重新执⾏⽇志上的这些内容，以弄清楚我应该读取哪个 page，但这会让写操作的速度变得⾮常快
3. 你不需要做额外的写操作来将这些dirty page写出到磁盘，你只需要追加⽇志条⽬即可
4. 共同点：和预写式理念相同，只不过日志结构存储没有page，没有table heap
##### 日志记录是否在同一个WAL buffer中
1. 它们是混合在一起的，有些⾼级系统会去决定某个事务是否允许去更新这个对象或者另⼀个对象
2. 假设我们允许它们这样做，并且它们也会这样做，我们只需将它们的⽇志记录添加到⽇志⽂件中
##### WAL实现
1. 事务提交的时候，我们会确保这些⽇志记录和buffer已经被保存到磁盘上了
2. 事务提交时是调⽤FSync将数据写出到磁盘的时候
3. DBMS应该在什么时候将这些dirty record写出到磁盘：对于这个log buffer，我们需要能够去redo⼀个事务所做的所有修改，在这个page写出到磁盘前，这些修改对应的log 记录应该写出到磁盘
4. 当该事务提交时，这些page代表的修改并不会⽴⻢刷出到磁盘，直到⽇志记录已经被刷出到 磁盘为⽌
##### 应用程序是否会中止
1. 是的，否则，如果你不想等待看到你所提交的内容。但你可能会丢失数据
2. 
##### WAL组提交
1. 在这种简单的形式中，你会有2个log buffer。所有⼈都会先往master中写⼊数据，当master中写满数据后，你会往后台这个buffer中写⼊数据。我需要去调⽤FSync，你知道的，这样做需要花点时间(知秋注:背后隐含了⼀个锁同步)
2. 设置定时刷出到磁盘上，
##### 缓冲池策略
1. no-force + steal：它使⽤的是预写式⽇志，它的运⾏时性能是最好的
2. 运行时性能：指的是，当我执⾏事务的时候，它维护所有信息的速度有多快
3. 
#### 日志模式
1. 如果使⽤的是预写式⽇志，那你就需要Undo和Redo
##### 物理日志
1. 我们会去记录你对数据库中某个特定位置所做的低级层⾯的字节修改，并且你知道如何撤销你 的修改
2. 如果我在我的事务中要更新10亿条tuple，那么，我就需要使⽤10亿条与这些低级层⾯物理修改所对应的⽇志记录
##### 逻辑日志
1. 即你只记录那些你对数据库所做的⾼级层⾯的修改
2. 可以使用一条语句更新10亿条数据，
3. 我难以去弄清楚在系统发⽣崩溃前，我对数据库所做的修改实际有哪些已经被写 ⼊磁盘了
4. 逻辑方案保存的数据较少但是但这会让数据库系统恢复时所付出的成本更加昂贵
##### 物理逻辑页面
1. 即你⽆须去保存你对数据库所做的那些低级层⾯，你仍然可以做到：它⾜够的低级层⾯，即你可以说，你看，在这个page处，我正在修改这个 object 对象
2. 但你不需要像在物理⽇志记录（physical logging）中那样获得货真价实的差异，你只需要去说，此处有⼀个逻辑，我想要对它进⾏⼀个修改
3. 大多数系统使用的方式
4. 但基本来说，在这个⽇志中，需要在你同时要将索引修改写出到数据库中，因为如果我的索引匹配不到内存，我不想在恢复时从头开始重建它，⼤多数DBMS 也会将事务修改涉及到的索引记录在⽇志之中
5. 对于physical logical logging，你可以说，在这个page，这个slot number处，我想去做⼀些低级层⾯属性的修改。即你需要这些额外的间接信息，⽐如slot number (即图中的offset)、page。即你需要这些额外的间接信息，⽐如slot number (即图中的offset)、page
6. 通过这种⽅式，DBMS 会提前对修改进⾏⼀个字节⼀个字节的复制，在发⽣崩溃后，你会有⼀些摆动空间（即某些部分会存在两份不同的数据），可以通过不同⽅ 式实际重新应⽤这些内容，并且还原后仍可以恢复到正确的状态

#### 检查点
1. 我们会将我们buffer pool中所有dirty page刷出到磁盘，并往我们的⽇志记录中添加⼀个checkpoint条⽬，以此来表示所有的dirty page都被持久化到了磁盘上
2. 在检查点可能有的事务提交了，但是有的事务正在执行，需要回到检查点，并弄清楚它们实际做了什么事情，以此来让我的数据回归正轨
3. t2和t3事务，t2在崩溃前提交了，但是t3没有我就知道我想去撤销它所做的修改
4. 因为有一个事务，它对一堆page进行更新，我不希望遇到这种情况，或者可能是我必须做⼀些实际的⼯作才能弄清楚（知秋注：即⼏个事 务交错在⼀起，要去弄清楚谁提交了，谁在执⾏中，谁挂掉了）
##### demo
1. ⽐如，我要更新20个page，⽽我的checkpoint 会将事务已修改的前10个page刷出到磁 盘,然后在checkpoint 运⾏时，它修改了其他内容，但我没有将这些内容刷出到磁盘
2. 我不想弄清楚那些checkpoint 附近所发⽣的事情。
3. 另一个事情时需要多久设置一个checkpoint，这也会消耗性能
4. 因为我们正在写出dirty page时，会降低我们⽇志写出磁盘速度。在许多系统中有很多分离的磁盘，同步进行时并不会放慢速度
5. 再次，现在，我在运⾏时出现了checkpoint，需要将dirty pages刷出到磁盘
6. 我可以为磁盘清理出pages以在缓冲池(buffer pool)中获取新空间以使其他事务继续运⾏
##### 检查点-频率
1. 你制作checkpoint的频率取决于你的具体实现，⽐如每分钟或者每秒就制作⼀份checkpoint。恢复的速度就很短
2. 因为我就⽆须跑到⽇志很前⾯的地⽅去弄清楚哪些数据被持久化了，因为我记录checkpoint的频率⾮常频繁
3. 因为这个原因，这就会让我的运⾏时性能降低，
4. 另一种方案：满足一定数量
##### 简单方案：一致性检查点
1. 暂停所有事务的执行，并将它们的相关dirty page刷出到磁，落地再执行事务
##### 恢复时为什么不做unDo
1. 因为我们关注的是那些实际已经落地到磁盘的修改
2. 你可能会对⽇志进⾏多次遍历,你会重新执⾏所有操作
3. 当你进行重新操作的时候，我看到这个事务并未被提交，然后你在⽇志上回退，你会基于它撤销（undo）那些需要撤销的修改，这样，你的系统玩起来就会很安全，你会经常undo的，我们可以对它们进⾏⼀些优化，但我不觉得⼤部分⼈会做
