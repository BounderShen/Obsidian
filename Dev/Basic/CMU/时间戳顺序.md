#### 前言
##### timestamp allocation
1. 数据库需要维护这些，时间戳是单调增加的，随着时间的流逝而增加的，且值是唯一的
2. 不同的时间戳协议它们拥有的机制也不同
3. 从事务执⾏的时候，它们会将这些时间戳分配给事务
4. 特性：这些时间戳不⼀定要和挂钟时间所对应，因为我们可以在事务执⾏期内的任意时间点给事务分配时间戳。不⼀定是要在刚拿到事务的时候给它分配时间戳，也不⼀定要在事务提交的时候分配时间戳。
5. 不同的协议有着不同的机制，它们会在某个时间点将时间戳分配给事务，实际上，你可以通过⼀些不同的⽅法来确定某个事务的时间戳是什么
##### 多个种策略
1. 使用CPU，使用分布式数据库系统时，就很难保证时间是同步的。第二，可以将时间回调，什么情况下会进行回调？在进行机器同步的时候，时间轴可能回调
2. 逻辑计数器：
	1. 在不需要⽤到锁的情况下，它可以快速增加它的值，⽐如，你可以进⾏原⼦性相加或者类似的操作；如果你的值超过了32位，这会发⽣什么呢？会用完你的时间戳，你可以将它回滚。计数器就会往回走了
3. 大部分系统都是混合方案，通过让时间戳和物理计数器以及逻辑计数器进⾏匹配，以此确定所有东⻄都是正常⼯作的
##### 基于时间戳协议 
##### basic T/O
1. 对每个元组添加读时间戳和写时间戳（最近的），事务开始的时候分配时间戳
2. 当事务执⾏它⾥⾯的操作时，它需要确保它可以利⽤与该tuple相关的时间戳来读取这个tuple
3. 当发生中止事务时（事务时间戳比元组时间戳大），需要确保你所开始执⾏的新事务所携带的新时间戳要⽐你⼀开始执⾏该事务时的时间戳要新
4. 时间戳和写时间戳相同。意味着可以进行读取，这种是重复读
5. 被允许操作了，会将元数据的中的时间戳改为事务的时间戳
6. 更新时间戳后，你必须将该tuple的副本保存到⼀个只有你可⻅的本地私有⼯作空间中去，这样的话，你就可以确保你可以做到可重复读
##### 问题
1. 什么时候更新时间戳
##### basic T/O write
1. 如果事务的时间戳小于读的时间戳或者写的时间戳，则重启该事务并将新的时间戳分配给它，然后再执行整个过程
2. 你也必须要制作⼀个本地副本，以此来⽀持可重复读
##### 托马斯写入规则
1. 如果你的时间戳⼩于该对象的read timestamp，你依然需要中⽌该事务，并开启⼀个携带新时间戳的事务
2. 但如果该时间戳⼩于该对象的write timestamp，有⼀个较新的事务已经修改过该对象了，实际上，你可以忽略掉这个写操作，你现在可以读取这个对象的本地存储副本，但从外界来看，将这个写操作忽略掉是Ok的。不用去更新该写操作的时间戳或者值
##### 可恢复的调度
1. ⼀个事务只有当它所依赖数据的对应事务已经都提交的情况下，它再进⾏提交，这样的 schedule是可恢复的
2. 想要确保：如果你读取了另⼀个事务所更新的值，该事务能在你提交之前提交，basic timestamp ordering并不能为你保证这⼀点
3. 比如：一个事务读取另一个事务修改之后的值，但修改的那个事务中止了，就会出现问题。对于时间戳协议这是允许的
##### basic T/O 性能问题
1. 开销很大，进行读写操作需要将数据复制到本地空间中
2. 问题：我们在执⾏那些⻓时间运⾏的事务时，会遇上starvation的状况，那些执⾏时间不⻓的事务会快速更新1个或2个tuple，这会让那些执⾏时间很⻓的事务被中⽌并重启
3. 
##### 乐观并发控制
##### OCC PHASES
1. 读阶段：跟踪读写事务和存储他们修改的值在私人工作空间
2. 验证阶段：事务提交，检查是否与其他事务发生冲突
3. 写阶段：落地到数据库中，你会以原⼦的⽅式将你的所有修改都落地到主数据库中
4. 读阶段拿到的是无穷大的时间戳，只有进入验证阶段才会分配一个时间戳，对副本处理时，需要将时间戳改为验证时所分配的时间戳
5. validation phase指的是：数据库要确保它所⽣成的schedule是Serializable的，或者是Conflict Serializable的
##### OCC 序列化验证
1. 它需要⼀种全局视野，能够看到系统中所有正在运⾏的活跃事务，那么，你就能看到每个事务在系统中所做的所有修改。通过这种机制来决定事务的执行顺序
2. 我们想让Validation和Write这两个阶段按顺序执⾏，在Validation阶段会有⼀个很⼤的latch，它⽤来确保⼀次只有 ⼀个事务在执⾏验证操作
##### OCC 验证阶段
1. 你拿到⼀个时间戳后，接着，你就会使⽤这个时间戳去查看系统中所有其他并发执⾏的事务。以此来确保你的read set和write set不会相交
2. 当准备好验证时，本质上来讲，你就会去调⽤commit，接着，数据库就会执⾏validation阶段。因为它能看到数据库系统中所有的事务，我们可以找到所有新来的事务，以及所有的事务，并确保所有东⻄都能放在⼀起
##### OCC backward validation
1. 当某个事务准备好提交的时候，假设T2准备好提交了，你就会去查看该系统中所有较⽼的事务
2. 我们将我们查看的这部分区域叫做validation scope（验证作⽤域），如果我们对T2使⽤backward validation，那么这部分就是T2的validation scope。可能发生的情况：T1更新了某个数据，该数据应该被T2所读取到，但实际并没有，因为T1是对它的私有副本所做的修改
3. 会找到所有并行执行但是没有提交的的事务
4. 验证成功之后，就落地到系统中
##### 两种情况
1. 你原有事务中的写操作要在Tj这个时间戳更⼤的事务执⾏任何操作前完成。本质上来讲，你可以将这些事务合并为⼀个，然后你就得到了⼀个Serial execution
2. 如果Tj在开始执⾏它的写阶段之前，Ti就完成了它的⼯作。在这种情况下，我们事务中写操作要处理的东⻄不会与其他事务读操作涉及的东⻄相交。即其他事务不会去读取任何我们要写⼊的东⻄
##### OCC validation step 2
1. read set 和write set 不能相交也就是等于空集
2. 确保的是write set不与其他相交
3. 在冲突很多的Workload中，两阶段锁和乐观并发协议通常来讲都不行，效果几乎都一样
4. 在两阶段锁中，它⾥⾯存在着⼤量争抢锁的情况，你需要让事务去等待获取这些热⻔的lock，这⾥你会遇上那些做了很多⽆⽤功的事务，它们在最后的时候被中⽌
##### OCC中
1. 该协议会让你在验证阶段的时候分配时间戳,因为你会将这些实际的检查⼯作延迟到你准备提交事务的时候再做。Basic timestamp ordering表示，我会对我要执⾏的每个操作进⾏检查，以确保这是⼀个有效 操作
2. 即使你是在进⾏读操作的时候，你也依然需要制作⼀份本地副本以⽀持可重复读
3. 使⽤OCC的时候，我们会有⼀些开销，因为你需要去维护你想要进⾏读写操作的那些对象的本地副本
4. 另⼀件事情是，验证阶段和写阶段会按顺序执⾏，⼀次只会有⼀个事务进⾏验证。在真正的系统中，你可以进⾏并⾏验证和并⾏写，但在这些情况下，这些阶段会变成⼀个巨⼤的瓶颈
5. 从逻辑上来讲，你依然必须确保你要去维护你所查看的数据结构的物理正确性
6. 在执⾏验证阶段的时候，你会看到所有这些数以千计的事务，我不得不深⼊其中通过⼀种可以保证⼀致性的操作⽅式来 查看read和write set，我通过获取latch来让它们保持⼀致
7. 逻辑不相交，但是物理上在抢夺同一个数据结构，即使在逻辑上read set和write set是不相交的，但它们依然存在着争抢问题
8. 数据表中无法看到这些，在我验证的时候，我需要查看其它所有事务的本地数据副本
##### 执行验证的时候，必须查看read /write set 确保不相交
1. 是的，但是还可以进行数据修改，因为事务正在执行。需要获取latch与一种一致性方式来保证执行操作ok
##### 分区基于 T/O


##### 隔离级别
