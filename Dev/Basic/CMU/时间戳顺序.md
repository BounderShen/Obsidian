#### 前言
##### timestamp allocation
1. 数据库需要维护这些，时间戳是单调增加的，随着时间的流逝而增加的，且值是唯一的
2. 不同的时间戳协议它们拥有的机制也不同
3. 从事务执⾏的时候，它们会将这些时间戳分配给事务
4. 特性：这些时间戳不⼀定要和挂钟时间所对应，因为我们可以在事务执⾏期内的任意时间点给事务分配时间戳。不⼀定是要在刚拿到事务的时候给它分配时间戳，也不⼀定要在事务提交的时候分配时间戳。
5. 不同的协议有着不同的机制，它们会在某个时间点将时间戳分配给事务，实际上，你可以通过⼀些不同的⽅法来确定某个事务的时间戳是什么
##### 多个种策略
1. 使用CPU，使用分布式数据库系统时，就很难保证时间是同步的。第二，可以将时间回调，什么情况下会进行回调？在进行机器同步的时候，时间轴可能回调
2. 逻辑计数器：
	1. 在不需要⽤到锁的情况下，它可以快速增加它的值，⽐如，你可以进⾏原⼦性相加或者类似的操作；如果你的值超过了32位，这会发⽣什么呢？会用完你的时间戳，你可以将它回滚。计数器就会往回走了
3. 大部分系统都是混合方案，通过让时间戳和物理计数器以及逻辑计数器进⾏匹配，以此确定所有东⻄都是正常⼯作的
##### 基于时间戳协议 
##### basic T/O
1. 对每个元组添加读时间戳和写时间戳（最近的），事务开始的时候分配时间戳
2. 当事务执⾏它⾥⾯的操作时，它需要确保它可以利⽤与该tuple相关的时间戳来读取这个tuple
3. 当发生中止事务时（事务时间戳比元组时间戳大），需要确保你所开始执⾏的新事务所携带的新时间戳要⽐你⼀开始执⾏该事务时的时间戳要新
4. 时间戳和写时间戳相同。意味着可以进行读取，这种是重复读
5. 被允许操作了，会将元数据的中的时间戳改为事务的时间戳
6. 更新时间戳后，你必须将该tuple的副本保存到⼀个只有你可⻅的本地私有⼯作空间中去，这样的话，你就可以确保你可以做到可重复读
##### 问题
1. 什么时候更新时间戳
##### basic T/O write
1. 如果事务的时间戳小于读的时间戳或者写的时间戳，则重启该事务并将新的时间戳分配给它，然后再执行整个过程
2. 你也必须要制作⼀个本地副本，以此来⽀持可重复读
##### 托马斯写入规则
1. 如果你的时间戳⼩于该对象的read timestamp，你依然需要中⽌该事务，并开启⼀个携带新时间戳的事务
2. 但如果该时间戳⼩于该对象的write timestamp，有⼀个较新的事务已经修改过该对象了，实际上，你可以忽略掉这个写操作，你现在可以读取这个对象的本地存储副本，但从外界来看，将这个写操作忽略掉是Ok的。不用去更新该写操作的时间戳或者值
##### 可恢复的调度
1. ⼀个事务只有当它所依赖数据的对应事务已经都提交的情况下，它再进⾏提交，这样的 schedule是可恢复的
2. 想要确保：如果你读取了另⼀个事务所更新的值，该事务能在你提交之前提交，basic timestamp ordering并不能为你保证这⼀点
3. 比如：一个事务读取另一个事务修改之后的值，但修改的那个事务中止了，就会出现问题。对于时间戳协议这是允许的
##### basic T/O 性能问题
1. 开销很大，进行读写操作需要将数据复制到本地空间中
2. 问题：我们在执⾏那些⻓时间运⾏的事务时，会遇上starvation的状况，那些执⾏时间不⻓的事务会快速更新1个或2个tuple，这会让那些执⾏时间很⻓的事务被中⽌并重启
3. 
##### 乐观并发控制
##### OCC PHASES
1. 读阶段：跟踪读写事务和存储他们修改的值在私人工作空间
2. 验证阶段：事务提交，检查是否与其他事务发生冲突
3. 写阶段：落地到数据库中，你会以原⼦的⽅式将你的所有修改都落地到主数据库中
4. 读阶段拿到的是无穷大的时间戳，只有进入验证阶段才会分配一个时间戳，对副本处理时，需要将时间戳改为验证时所分配的时间戳
5. validation phase指的是：数据库要确保它所⽣成的schedule是Serializable的，或者是Conflict Serializable的
##### OCC 序列化验证
1. 它需要⼀种全局视野，能够看到系统中所有正在运⾏的活跃事务，那么，你就能看到每个事务在系统中所做的所有修改。通过这种机制来决定事务的执行顺序
2. 我们想让Validation和Write这两个阶段按顺序执⾏，在Validation阶段会有⼀个很⼤的latch，它⽤来确保⼀次只有 ⼀个事务在执⾏验证操作
##### OCC 验证阶段
1. 你拿到⼀个时间戳后，接着，你就会使⽤这个时间戳去查看系统中所有其他并发执⾏的事务。以此来确保你的read set和write set不会相交
2. 当准备好验证时，本质上来讲，你就会去调⽤commit，接着，数据库就会执⾏validation阶段。因为它能看到数据库系统中所有的事务，我们可以找到所有新来的事务，以及所有的事务，并确保所有东⻄都能放在⼀起
##### OCC backward validation
1. 当某个事务准备好提交的时候，假设T2准备好提交了，你就会去查看该系统中所有较⽼的事务
2. 我们将我们查看的这部分区域叫做validation scope（验证作⽤域），如果我们对T2使⽤backward validation，那么这部分就是T2的validation scope。可能发生的情况：T1更新了某个数据，该数据应该被T2所读取到，但实际并没有，因为T1是对它的私有副本所做的修改
3. 会找到所有并行执行但是没有提交的的事务
4. 验证成功之后，就落地到系统中
##### 两种情况
1. 你原有事务中的写操作要在Tj这个时间戳更⼤的事务执⾏任何操作前完成。本质上来讲，你可以将这些事务合并为⼀个，然后你就得到了⼀个Serial execution
2. 如果Tj在开始执⾏它的写阶段之前，Ti就完成了它的⼯作。在这种情况下，我们事务中写操作要处理的东⻄不会与其他事务读操作涉及的东⻄相交。即其他事务不会去读取任何我们要写⼊的东⻄
##### OCC validation step 2
1. read set 和write set 不能相交也就是等于空集
2. 确保的是write set不与其他相交
3. 在冲突很多的Workload中，两阶段锁和乐观并发协议通常来讲都不行，效果几乎都一样
4. 在两阶段锁中，它⾥⾯存在着⼤量争抢锁的情况，你需要让事务去等待获取这些热⻔的lock，这⾥你会遇上那些做了很多⽆⽤功的事务，它们在最后的时候被中⽌
##### OCC中
1. 该协议会让你在验证阶段的时候分配时间戳,因为你会将这些实际的检查⼯作延迟到你准备提交事务的时候再做。Basic timestamp ordering表示，我会对我要执⾏的每个操作进⾏检查，以确保这是⼀个有效 操作
2. 即使你是在进⾏读操作的时候，你也依然需要制作⼀份本地副本以⽀持可重复读
3. 使⽤OCC的时候，我们会有⼀些开销，因为你需要去维护你想要进⾏读写操作的那些对象的本地副本
4. 另⼀件事情是，验证阶段和写阶段会按顺序执⾏，⼀次只会有⼀个事务进⾏验证。在真正的系统中，你可以进⾏并⾏验证和并⾏写，但在这些情况下，这些阶段会变成⼀个巨⼤的瓶颈
5. 从逻辑上来讲，你依然必须确保你要去维护你所查看的数据结构的物理正确性
6. 在执⾏验证阶段的时候，你会看到所有这些数以千计的事务，我不得不深⼊其中通过⼀种可以保证⼀致性的操作⽅式来 查看read和write set，我通过获取latch来让它们保持⼀致
7. 逻辑不相交，但是物理上在抢夺同一个数据结构，即使在逻辑上read set和write set是不相交的，但它们依然存在着争抢问题
8. 数据表中无法看到这些，在我验证的时候，我需要查看其它所有事务的本地数据副本
##### 执行验证的时候，必须查看read /write set 确保不相交
1. 是的，但是还可以进行数据修改，因为事务正在执行。需要获取latch与一种一致性方式来保证执行操作ok。会产生一些开销
##### 分区基于 T/O
1. 将数据库进行水平分区，我想能够通过时间戳来对该分区所涉及的事务进⾏排序，让它们以Serial Order的顺序 执⾏
2. 如果我的事务按顺序执⾏，没理由使用锁
3. 如果你需要访问多个数据库分区，那么情况就会变得有些复杂，
4. 因为所有的事务都会放在⼀个队列中，在数据库中，我们会以单线程的⽅式来执⾏这些事务，所以不存在并发行为
5. 如果我们将数据库分区分的粒度越细，那么我们所获得的并⾏性就越⾼，这样的话，每个事务执⾏的速度就会变得更快
6. 实际上，如果你的系统也⽀持这种Partition-Based Timestamp Ordering的话，你的系统就 会⾮常成功
7. 当其他事务出现的时候，它们会排队获取这个latch，本质上来讲，我们会给它们分配⼀个时间戳，当轮到它们执⾏的时候，它们就会开始对该数据库分区进⾏操作
##### 基于T/O 分区的读
1. 跨分区访问数据，需要中止并重启该事务
2. 假设我们之前的应⽤程序服务器想通过⼀个事务来对两个不同分区内的customer信息进 ⾏修改，那么情况就会变得复杂，在我可以执⾏任何操作之前，我必须要获取这个分区的lock，以及另⼀个分区的lock。有时不需要知道有哪些分区，也不需要接触他们
3. 有些系统在它们运⾏的时候，它们会使⽤⼀种推测或者侦查模式来弄清楚我需要访问的 分区有哪些
4. 接着，如果回滚的话，它提前需要获取到所有的lock，接着开始执⾏
##### 基于T/O 分区的写
1. 在DBMS同一时间只有一个事务执行，我可以在数据库中直接更新数据
2. 我需要⼀些额外逻辑来确保当我中⽌事务时，我要撤销这些已经执⾏的修改，但我可以在不需要制作本地副本的情况下做到这点
3. 这样我就减少了通常存在于OCC系统中那些数据复制所带来的开销
4. 在某种情况下，如果我试着对⼀个tuple进⾏修改，它所在的分区与我事务所在的分区不是同 ⼀个分区。中止并重启该事务，接着获取这两个数据库分区的lock，然后执行该事务
5. 假设：T1、T2有两个事务，意识到需要去获取不同分区的锁，中止重启并获取锁，进入队列进行排队，会以顺序执行事务
##### 基于T/O 分区的性能问题
1. 如果数据库在开始执⾏这些事务前就知道这些事务需要⽤到哪些分区，那么这些系统的速度就 会很快
2. 你可以通过存储过程来补救⼀下，在存储过程中，你⽆须来回发送请求，数据库会在服务器端执⾏所有东⻄。这样可以更快地确定在事务执⾏过程中事务需要的lock有哪些
3. 拥有多种分区设置，你的有些分区可能就处于闲置状态
##### 动态数据库
1. 之前假设没有插入，插入会产生幻读如何解决：只有当元组加锁才可以访问元组
2. 使用条件锁：获取表达式上的锁，实现成本非常高
3. 层级锁
4. 索引锁：
	1. 如果在系统中，我有⼀个索引，我们在status这个字段上建⽴了索引，我所能做的事情就是，我会对索引中status="lit "的slot加锁，任何新的插⼊操作都需要去遍历索引，并对索引进⾏更新。它们无法获取到索引锁
5. Gap Lock：在索引中有⼀个空隙，我获取了该空隙对应的lock，如果另⼀个插⼊操作试图将符合（status='lit'）条件的tuple插⼊索引中的这个空隙，我们不允许它这么做
6. 最后一种方法：在事务提交前，我们进行反复扫描，你必须确保你读取到的所有东⻄都是在你提交事务前读取的。即读的数据在你提交这 ⼀刻，它就是最新的，若不是，就重启事务


##### 隔离级别
