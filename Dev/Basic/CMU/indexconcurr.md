1. 避免操作系统层面的锁
2. Futex：自旋锁，
3. 多个线程间通过使用我们的hash table 来进行交互的方式是有限的
4. 与B+树不同，B+树只有当你跳到内部节点才会释放latch。B+树在你进入某个节点以及跳到下个节点前必须持有一个latch，只有进入下一个Node时，才会将前一个node的latch释放掉
5. 对于线程2的优化：场景：当一个读锁正在读，一个线程请求写锁，可以先将写锁变成读锁看是否存在
6. 找到空槽之后需要进行相关标记，
7. 在B+树中，当线程往下遍历时，线程会通过一个栈来保存它一路上所持有的latch
8. 在某个时间点，当我在一个安全的节点时，我就可以释放掉该节点之前所有的节点上的latch
9. 从性能角度优先释放上层的锁
10. 当前节点未满可以释放上层的锁
36：49
##### 并发控制
1. 通过一种并发协议或者并发方案来保护数据方式
2. 强制所有访问数据结构的线程都使用某种协议
3. 关心逻辑正确性和物理正确性
#### latch 概述
##### Locks VS Latches
|   名称   | loacks       |   Latches    |
|:--------:| ------------ |:------------:|
| seperate | 事务         |     线程     |
| protect  | 数据库内容   | 内存数据结构 |
|   期间   | 进入事务     |   关键部分   |
|   模式   | 共享、更新、 |     读写     |
|          |              |              |
|          |              |              |
##### Latches mode
1. 读模式
2. 写模式
##### Latch实现
***OS 锁***
1. 单独使用
2. Futex: Fast userspace mutex；在用户空间中（进程中）使用一点内存（1bit），通过这个位置来尝试进行CAS操作，以获取Latch，获不到它，则默认使用更慢的mutex
#### 问题
##### OS层面调用mutex
1. 然后OS就表示，我知道你被这个mutex给阻塞了，你没法拿到这个latch （知秋注：并将你放 到⼀个等待队列中，等待调度器调度）
2. 让我告诉调度器来进⾏调度。这样你实际上就运⾏不了了
3. 代价昂贵的原因是：因为OS有它⾃⼰的内部数据结构，会使⽤latch来保护它们，你就会得知这个争抢失败的线程⽆法运⾏了
##### 自旋锁或者CAS
1. 因为在我们的现代CPU中，它⾥⾯有⼀条指令，使⽤这条指令可以在⼀个内存地址上进⾏单次CAS操作
2. 即检查这个内存地址上的值是否和我认为的值相等，相等则修改原来的值
##### 无法获得锁
1. 不管我做什么操作，latch的获取与释放都应该很快
2. 那么对等待的线程来说进⾏重试的速度就可能很快，因为不管谁拿着latch，它都会很快放弃这个latch
3. 但如果我觉得操作要花的时间太⻓了，那么我可能会对线程进⾏yield操作，让其他的线程先执⾏，或者就直接中断操作。
4. 我们没法在blocking OS mutex中做这个，即当我们试着去获取锁的时候，我们没有办法让线程做让出cpu资源这个事⼉（yield操作）。OS就会去接⼿，然后我们就阻塞了
##### 读写锁策略
1. 这也取决于我们想将这个latch⽤在哪种上下⽂中
2. 如果我们有这样⼀种数据结构，它不会涉及太多的写⼊操作，但这些写⼊是⾮常重要的
3. 那我们就会赋予写线程更⾼的优先级
#### hash table latch
1. 对hash table进行重新调整，我们通常会在Page header加一个全局latch
#### B+tree
##### latch crabbing
1. 基本上来讲，在B+ Tree中，当线程往下进⾏遍历时，线程会通过⼀个stack来保存它⼀ 路上所持有的latch
2. 在某个时间点，当我在⼀个安全的节点处时，我就可以释放掉该节点之前所有节点上的 latch
3. 在B+Tree中，线程会使⽤⼀个栈来保存它们向下遍历时所获取到的所有latch，⽽不是使⽤⼀ 个队列来进⾏处理
##### 更好的算法
1. 即⼤部分的线程不需要对叶⼦结点进⾏拆分或者合并操作
2. 在向下访问B+ Tree的时候，我所采⽤的是read latch，⽽不是write latch
3. 我在对叶⼦节点进⾏处理时，会使⽤write latch
4. 合并和拆分时：并在根节点处重启该操作，在向下遍历的时候获取write latch
5. 实际的数据库中：你的node的⼤⼩应该是8kb或者16kb，单个node就会有⼀⼤堆key
##### 可不可以从我们最后⼀次释放latch的地⽅重新开始
1. 图上这些ABCDE都是这些节点的逻辑标识符，但它们最终可能会分散在不同的page中，因此这些节点的page id可能会是不同的东⻄
2. 在我的栈中有page 123和page 456，然后，我去查找page 123时，我看到的是完全不同的东⻄
3. 因为我们⽆法假定这些节点的位置内容始终不变，除⾮我在这些节点上⾯加了latch
4. read latch会阻⽌任何⼈对这些节点进⾏写⼊和拆分操作，write latch则是阻⽌除我之外的⼈对这些节点进⾏修改
##### 实战中
1. 如果争⽤率很⾼的话，这种做法要⽐悲观锁来得慢
2. 但⼀般来讲，对于这些我所讨论的数据结构来说，实际上，使⽤这种乐观锁的机制，它的效果最好
3. 通常情况下，在page上使⽤悲观锁，实际上效果⾮常好。简单
##### page latch 还是slot latch
1. 你不能使⽤低级层⾯的slot latch，但你可以在page table中使⽤这个
2. 因为你可以去修改索引的物理结构,因此我得去更新指针,如果我需要进⾏拆分和合并操作
3. 为了移动这些key，我需要拿到与该节点相关所有key的latch（也会拿到相关上层节点的 latch）
4. ⼀般来讲你需要拿到的latch是关于整个page的，⽽不是slot
#### 叶子扫描
##### 原始的B+树没有兄弟指针，现在的大部分都有
1. 读锁遇到写锁时：重新执行该操作
2. 基本上来讲，在索引中会有⼀个retry循环，我会在索引上不断重新执⾏这个操作，直到操作成功为⽌。我们可以等待⼀段时间，⽽不是过于保守，直接将操作终⽌
##### 需要合并时
1. 使用乐观锁
2. 最简单的⽅式是，如果我最后没能得到我想要的，我就⽴⻢⾃裁，重新来过
##### 通常情况
1. 更新三个节点：当前、父节点、新节点
2. 子节点出现溢出的情况，延迟对父节点的更新，更新这棵树的全局信息中的一点点内容。某一时刻，有人来遍历这棵树的时候，我们再去更新这个节点
3. 有个全局的东西，每条线程启动时都会看到